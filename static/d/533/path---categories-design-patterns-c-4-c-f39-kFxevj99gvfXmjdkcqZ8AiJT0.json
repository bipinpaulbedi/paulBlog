{"data":{"site":{"siteMetadata":{"title":"paul blog","description":"thoughts, stories & ideas.","author":"Bipin Paul Bedi","siteUrl":"https://www.bipinpaulbedi.com"}},"allMarkdownRemark":{"totalCount":2,"edges":[{"node":{"id":"ed3d1d43-7c2b-57f8-b309-3f5b110c3ecb","excerpt":"Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes decision around…","fields":{"slug":"/2019-01-28-microservices-design-pattern/"},"html":"<p>Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes decision around maintainability and implementation of microservices. The evangelists behind microservice approach have built the case around speed, scalability and cohesion stating in that a microservice Change is easy, Units are small, scalability is semi infinite. So what is Microservice architecture? Microservices — also known as the microservice architecture — is an architectural style that structures an application as a collection of loosely coupled services, which implement business capabilities.</p>\n<p>We will discuss and summarize some of the implementation factors that have big impact on indicators of success in your project/software delivery viz:</p>\n<p><strong>Law of repository management</strong></p>\n<p>One of the most active moving part of micro services is code repositories. They can be categorised into two broader areas.</p>\n<ul>\n<li>Mono Repository i.e. keep all the services in the same repository</li>\n<li>Multiple Repositories i.e. keep separate repositories for each of the services</li>\n</ul>\n<p>Majority of microservices evolve over a period of time and it has been observed that based on team and organisation structures derives the strategy adopted for code management. Usually it naturally tends towards multiple repository pattern due of diverse practices followed in an organization among various units. This results in poor code reusability but also provides clear boundaries of ownership. The problem of reusability can be resolve by implementing re-usable package, e.g. nugets for .net or npm for node etc. As the number of services grows it becomes difficult to debug and cross teams development. Moreover overall platform knowledge becomes fragmented and abstract due to focused development teams.</p>\n<p>For a larger project it is recommended to use Mono repository with clear segregation of domain functionality and shared core reusability. This brings standardisation is development style and practices. It provides better integration capabilities and debugging at the cost of larger code base. Most programming framework provides modular development approach where we can leverage best of both world of mono repo for development and multi repo for build and release.</p>\n<p><strong>Law of separation of concern</strong></p>\n<p>The most common dilemma that microservice bring into an architects plate is regarding granularity of functionality. As per recommended practice the domain driven development leads to correct size of bounded context which is articulated based on various business activities and influence. Usually, in real world it has been noticed that business units and generated based on software boundaries. Nevertheless using microservices does not implies less code, rather it focus on maintainability and scalability. If you are planning to create a microservice for each functionality then it is definitely planning for disaster. Majority of segregation shall be based on domain but under special scenarios it is absolutely fine to deviate and create a separate service based on technical feature, e.g. email service, notification service etc.</p>\n<p>The mutual independence across multiple microservices is the core principle behind this architecture. Each service shall ideally implement its own data persistence and caching capabilities. The owner service defines the strategy to create, manipulate and consume service. The external services should not be entertaining data access directly but shall only pass through owner service interfaces only.</p>\n<p>The cross cutting concerns such as authentication shall be abstracted to gateways such as azure api management, <a href=\"http://threemammals.com/ocelot\">ocelot</a>. In certain scenarios a aggregator microservice might be required from client or as a server rapper to avoid multiple dependency hell.</p>\n<p>For a more complex front end, a small microservice shall be created for each unit of user interface to process data and serve it to client. This pattern is usually know as ui microservice or backend for front end design.</p>\n<p><strong>Law of eventual consistency</strong></p>\n<p>Since each service is responsible for consistency and reliability of its data the cross domain data passing is performed via message passing. It does not result in ACID [atomic, consistent, isolated, durable] principles as these updates are not happening in transaction. This is can be solved using two phase commit but will eventually result in high coupling and the core principle of microservices are violated. The microservice architecture is an advocate of CAP theorem i.e. consistent, available and partition tolerant. To achieve the desired benefits of microservices the eventual consistency is implemented via</p>\n<ul>\n<li>\n<p>Event sourcing - We can query an application’s state to find out the current state of the world, and this answers many questions. However there are times when we don’t just want to see where we are, we also want to know how we got there.\nEvent Sourcing ensures that all changes to application state are stored as a sequence of events. Not just can we query these events, we can also use the event log to reconstruct past states, and as a foundation to automatically adjust the state to cope with retroactive changes. e.g. database event logs, similar implementation can be adopted for business events and each micro services can perform action independently to bring system to desired state eventually.</p>\n</li>\n<li>\n<p>CQRS - CQRS stands for Command Query Responsibility Segregation. It’s a pattern that I first heard described by Greg Young. At its heart is the notion that you can use a different model to update information than the model you use to read information. The micro service can process data and keep up to date information for serving Realtime need but can update the core system from log. e.g. a notification for ecommerce order placement can be served separately to update in erp system.</p>\n</li>\n<li>\n<p>Message/Service Bus - For event based message passing in microservice either a direct call to the service can be initiated or a message broker such as service bus can be implemented for asynchronous communication maintaining the high demand services to scale to serve client needs and keeping background jobs instance low.</p>\n</li>\n</ul>\n<p>The above eventual consistency also require coordination of execution. The solution is defined as saga. Implement each business transaction that spans multiple services as a saga. A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.</p>\n<p>There are two ways of coordination sagas:</p>\n<ul>\n<li>Choreography - each local transaction publishes domain events that trigger local transactions in other services</li>\n<li>Orchestration - an orchestrator (object) tells the participants what local transactions to execute</li>\n</ul>\n<p><strong>Law of scalable deployment</strong></p>\n<p>Easy deployment and scalability is the key feature that bought microservices into architects tool box. There are various containerisation frameworks/application that can compile into deployable image that is ready to scale. Application containerization is an OS-level virtualization method used to deploy and run distributed applications without launching an entire virtual machine (VM) for each app. Multiple isolated applications or services run on a single host and access the same OS kernel. Application containers include the runtime components — such as files, environment variables and libraries — necessary to run the desired software. Application containers consume fewer resources than a comparable deployment on virtual machines because containers share resources without a full operating system to underpin each app.</p>\n<p>The most common app containerization technology is Docker, specifically the open source Docker Engine and container based on universal runtime runC. The main competitive offering is CoreOS’ rkt container engine that relies on the App Container (appc) spec as its open, standard container format, but it also can execute Docker container images.</p>\n<p>Though containerisation is not required to develop and run microservices but these two concepts have be tied together as complementary services to generate maximum benefit. The recommended practice is to deploy services using orchestrator such as Azure Kubernetes services, AWS fargate where that can create a instance for public or private registry such as docker hub, Azure container service etc. You can deploy multiple container on one host or have one host per container.</p>\n<p>Now Azure app service has capability to run docker image but usually with orchestrators in place, a cluster such as docker swarm, azure service fabric, azure service fabric mesh is usually used as deployment engine.</p>\n<p>Since these dynamic addition or removal of images may result is multiple end points thus a service discover provider is required to let the traffic routed to healthy end points only.</p>\n<p><strong>Law of green initiation</strong></p>\n<p>When working on a green field project multiple design pattern help us structure the system. But following key principles are must have for robust system viz:</p>\n<ul>\n<li>\n<p>Resilience - When a system is under faulty state due to certain unexpected events, the microservice shall be monitored correctly and a new backup service shall immediately become active to minimize the loss of data. If the service or backup is not available then alternate application to keep track of operation shall cover during the down time. Failure in one service shall not affect other.</p>\n</li>\n<li>\n<p>Failure - This is extension of above mentioned principle. If a service fails then the dependent service shall have some mechanism to track status and reduce resource wastage. The service might fail temporarily due to some network issue, thus a retry policy shall be applied. A more advanced mechanism would be implementing circuit breaker where after a certain retry it stops sending more message to failed microservice and only pass a certain requests in between to check for resume the status.</p>\n</li>\n<li>\n<p>Availability - Apart from expected and unexpected coding fault recovery the ability to maintain uptime is core requirement. Thus having geo-distributed redundant implementation is shall be part of implementation strategy.  </p>\n</li>\n<li>\n<p>Dev-ops - With high scalable environment the automated deployment and ability to version control the services leads to a stable solution. The service discover shall consider service versioning before routing requests.</p>\n</li>\n<li>\n<p>Scalability - Using ready to deploy light weight images as container shall allow individual service to scale to meet the growing demand.</p>\n</li>\n</ul>\n<p><strong>Law of brown transition</strong></p>\n<p>When transitioning from a brownfield project it requires more effort to make sure the stability f the system is not affected. In these scenarios the Strangler pattern comes to the rescue. The Strangler pattern is based on an analogy to a vine that strangles a tree that it’s wrapped around. This solution works well with web applications, where a call goes back and forth, and for each URI call, a service can be broken into different domains and hosted as separate services. The idea is to do it one domain at a time. This creates two separate applications that live side by side in the same URI space. Eventually, the newly refactored application “strangles” or replaces the original application until finally you can shut off the monolithic application.</p>\n<p><strong>Law of implementation patterns</strong></p>\n<p><strong>Law of communication</strong></p>\n<p><strong>Law of Monitoring</strong></p>","frontmatter":{"date":"January 28, 2019","title":"9 laws of architecting microservices","categories":"design-patterns"}}},{"node":{"id":"e0ec1d27-f812-5cad-afe8-e1dc91abf91e","excerpt":"As per Wikipedia, Design thinking is the cognitive process from which design concepts (e.g. ideas for products) emerge. Design thinking is…","fields":{"slug":"/2018-10-10-coding-blueprint-for-pragmatic-rest-api-developers/"},"html":"<p>As per Wikipedia, Design thinking is the cognitive process from which design concepts (e.g. ideas for products) emerge. Design thinking is related to, but is different from problem-solving, decision-making, creativity, sketching and prototyping. During design thinking, the designer’s attention oscillates between their understanding of a problem context and their ideas for a solution. New solution ideas lead to a deeper understanding of the problematic context, which in turn triggers more solution ideas.</p>\n<p>When your focus acts like a pendulum between problem context and the creative solution then you are bound to wear multiple hats. The irony as the developer when designing API is that your clients are other developers.\nOver the past decade after working under some fine mentors the summary of the learning can be stated as “Think of developing API endpoints for a command line interface, possibly it will result in self-understandable, complete solution you are seeking”.</p>\n<p>This post is inspired by eBook published by APIgee highlighting the best practiced for REST design. As an API designer, I have gone through some challenges myself, viz.</p>\n<p><strong>What should be my base URL?</strong></p>\n<p>Keep it short and simple. Try to use nouns and keep verbs out of your base URL. To smartly cover all possible scenario use HTTP verb standard.\nEg.</p>\n<table>\n<thead>\n<tr>\n<th>Resource</th>\n<th align=\"center\">POST</th>\n<th align=\"center\">GET</th>\n<th align=\"center\">PUT</th>\n<th align=\"center\">DELETE</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td align=\"center\">create</td>\n<td align=\"center\">read</td>\n<td align=\"center\">update</td>\n<td align=\"center\">delete</td>\n</tr>\n<tr>\n<td>/users</td>\n<td align=\"center\">create a new user</td>\n<td align=\"center\">list users</td>\n<td align=\"center\">bulk update users</td>\n<td align=\"center\">delete all users</td>\n</tr>\n<tr>\n<td>/users/1234</td>\n<td align=\"center\">error</td>\n<td align=\"center\">show user</td>\n<td align=\"center\">update if exists or error</td>\n<td align=\"center\">delete user</td>\n</tr>\n</tbody>\n</table>\n<p>The point is that developers probably don’t need the chart to understand how the API behaves. They can experiment with and learn the API without the documentation.</p>\n<p><strong>Shall I use plurals or singular nouns?</strong></p>\n<p>The recommended practice is to use plurals since the first API being tested by developers is most probably GET and GET /users to list all users make natural sense. Irrespective whatever you choose, be consistent to avoid confusing your API consumers. Moreover, concrete names are better than abstract ones. Eg. Having an endpoint like /blogs or /videos over abstract names like /items or /contents can help the consumer to identify resources more conveniently.<br>\nYou also want to expose a manageable number of resources. Aim for concrete naming and keep the number of resources between 12 and 24.</p>\n<p><strong>How should the relations and associations be exposed in API?</strong></p>\n<p>Resource always have relationships with other resources. oData standard makes it easier for developers to navigate resource and its association using metadata, it can be also let to exposing your information schema.<br>\nThe recommended practise is to follow ‘resource/identity/resource’ model eg. /users/1234/department. It’s not uncommon to see people string these together making a URL 5 or 6 levels deep. Remember that once you have the primary key for one level, you usually don’t need to include the levels above because you’ve already got your specific object.</p>\n<p><strong>How do we handle the complexity of pagination, partial response, filters etc.?</strong></p>\n<p>Make it simple for developers to use the base URL by putting optional states and attributes behind the query string question mark. E.g. GET /users?name=xxx<br>\nFor pagination request for limit and offset eg. GET /users?limit=50&#x26;offset=100 additionally, request fields to make it precise. Avoid using special characters in the query string. A good API always have defaults for pagination.<br>\nGood example /GET users?fields=name,gender<br>\nBad example /Get users:(name,gender)<br>\nWe also suggest including metadata with each response that is paginated that indicated to the developer the total number of records available. Use JSON-LD/HAL/Collection+JSON/SIREN/JSONAPI.ORG specifications as your starting point and don’t forget to be creative.</p>\n<p><strong>What is the recommended practice for error handling?</strong></p>\n<p>The developers learn to write code through error and trial, most important they rely on error messages during critical times for troubleshooting and resolving issues.<br>\nAs the best practice always serve the error messages with correct HTTP status codes, also include a verbose error message with as many details as possible. We highly recommend that you add a link in your description to add more information.<br>\nIn certain circumstances the framework used by developer intercepts the message and follows the default routine, thus developer may have no opportunity to inform his user appropriately. Thus, if you can provide a flag to suppress the status code and result in HTTP - 200 OK with actual status code and the message passed along with the payload.</p>\n<p><strong>Shall we version control the API?</strong></p>\n<p>Never release an API without a version and make the version mandatory. Keep the version naming simple and maintain compatibility with at least one version backwards for minimum 6-12 months.<br>\nSome developers advocate as to keep the version information in headers. But API can have breaking changes, thus being verbose and explicitly specifying version numbers in URL can help developers identify gaps early.</p>\n<p><strong>What about responses that don’t involve resources?</strong></p>\n<p>In certain cases, API calls that sends a response which is not a resource e.g. Calculate, Translate are not uncommon depending on the domain.\nIn these cases, Use verbs not nouns e.g. /convert?from=USD&#x26;to=AUD&#x26;amount=100<br>\nMake it clear in your API documentation that these “non-resource” scenarios are different, maybe in you swagger docs.<br>\n<br>\n<strong>How many formats shall we support?</strong></p>\n<p>Respect the HTTP header content-type and accepts e.g. Accept: application/json but let the user override using dot notation e.g. GET /user/1234.dat or GET /user/1234.xml<br>\nIf the default form is JSON, in the response properties try using camelCase for attributes as it is easier for the front-end developer to parse into objects with standard JavaScript conventions.</p>\n<p><strong>Any other tips and tricks?</strong></p>\n<p><em>Tip1:</em><br>\nA simple can be verb based resourceful API but for complex scenarios use google model\ne.g.<br>\n/search?q=xxx<br>\n/user?q=xxx<br>\n/location/1234/user=xxx – scoped<br>\n/search.xml?q=xxx – formatted  </p>\n<p><em>Tip2:</em><br>\nConsolidate API under a single domain with segregation for environments following a standard pattern e.g.\napi.xxx.com\nuat-api.xxx.com\ndev-api.xxx.com</p>\n<p><em>Tip3:</em><br>\nUse standard known authentication/authorization methodologies e.g. oAuth2.0 etc</p>\n<p><em>Tip4:</em><br>\nTry to complement your API with SDK</p>\n<p><em>Tip5:</em><br>\nUsing POST to emulate PUT, DELETE, PATCH. If your development platform or firewall rules prevent you from calling HTTP methods like PUT, PATCH or DELETE, use the X-HTTP-Method-Override header. Pass the method you want to use in the X-HTTP-Method-Override header and make your call using the POST method</p>\n<p><strong>What API design pattern is an ideal choice in most cases?</strong></p>\n<p>The architect must carefully evaluate available options and what suits the business domain and skill set of available developers in terms of project support and maintainability. But in most cases, an API Façade with mediate to complement can cover the majority of cases. This is covered in detail in another post.</p>","frontmatter":{"date":"October 10, 2018","title":"Developers guide to designing REST endpoints","categories":"design-patterns"}}}]}},"pageContext":{"category":"design-patterns"}}
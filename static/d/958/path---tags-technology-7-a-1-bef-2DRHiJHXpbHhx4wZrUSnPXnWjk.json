{"data":{"site":{"siteMetadata":{"title":"paul blog","description":"thoughts, stories & ideas.","author":"Bipin Paul Bedi","siteUrl":"https://www.bipinpaulbedi.com"}},"allMarkdownRemark":{"totalCount":2,"edges":[{"node":{"id":"ed3d1d43-7c2b-57f8-b309-3f5b110c3ecb","excerpt":"Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes decision around…","fields":{"slug":"/2019-01-28-microservices-design-pattern/"},"html":"<p>Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes decision around maintainability and implementation of microservices. The evanglists behind microservice approach have built the case around speed, scalability and cohesion stating in that a microservice Change is easy, Units are small, scalability is semi infinite. So what is Microservice architecture? Microservices — also known as the microservice architecture — is an architectural style that structures an application as a collection of loosely coupled services, which implement business capabilities.</p>\n<p>We will discuss and summarize some of the implementation factors that have big impact on indicators of success in your project/software delivery viz:</p>\n<p><strong>Law of repository management</strong></p>\n<p>One of the most active moving part of micro services is code repositories. They can be categorised into two broader areas.</p>\n<ul>\n<li>Mono Repository i.e. keep all the services in the same repository</li>\n<li>Multiple Repositories i.e. keep separate repositories for each of the services</li>\n</ul>\n<p>Majority of microservices evolve over a period of time and it has been observed that based on team and organisation stucutures derives the strategy adobted for code management. Usually it naturally tends towards multiple repository pattern due of diverse practices followed in an organization among various units. This results in poor code reusabiliy but also provides clear boundaries of ownership. The problem of reusability can be resolve by implementing re-usable package, e.g. nugets for .net or npm for node etc. As the number of services grows it becomes difficult to debug and cross teams development. Moreover overall platform knowledge becomes fragmented and abstract due to focused development teams.</p>\n<p>For a larger project it is recomended to use Mono repository with clear segrigation of domin functionality and shared core reusability. This brings standardisation is development style and practices. It provides better integration capabilities and debugging at the cost of larger code base. Most programming framework provides modular development approach where we can leverage best of both world of mono repo for development and multi repo for build and release.</p>\n<p><strong>Law of seperation of concern</strong></p>\n<p>The most common dilemma that microservice bring into an architects plate is regarding granuality of functionality. As per recomended practice the domain driven development leads to correct size of bounded context which is articulated based on various business activities and influence. Usually, in real world it has been noticed that business units and generated based on software boundaries. Nevertheless using microservices does not implies less code, rather it focus on maintainablity and scalability. If you are planning to create a microservice for each functionality then it is definately planning for diaster. Majority of seggrigation shall be based on domain but under special scenarios it is absoluty deviate and create a seperate service based on technical feature, e.g. email service, notification service etc.</p>\n<p>The mutual independence across multiple microservices is te core principle behind this architecture. Each service shall ideally implement its own data persistence and caching capabilities. The owner service defines the strategy to create, manipulate and consume service. The external services should not be entertaining data access directly but shall only pass through owner service interfaces only.</p>\n<p>The cross cutting concers such as authentication shall be abstracted to gateways such as azure api management, <a href=\"http://threemammals.com/ocelot\">ocelot</a>. In certain senarios a aggregator microservice might be required from client or as a server rapper to avoid multiple dependenct hell.</p>\n<p>For a more complex front end, a small microservice shall be created for each unit of user interface to process data and serve it to client. This pattern is usually know as ui microservice or backend for front end design.</p>\n<p><strong>Law of eventual consistency</strong></p>\n<p>Since each service is responsible for consistency and reliabiliy of its data the cross domain data passing is performed via message passing. It does not result in ACID [atomic, consitent, isolated, durable] principles as these updates are not happening in transaction. This is can be solved using two phase commit but will eventually result in high coupling and the core principle of microservices are violated. The microservice arctchitecture is an advocate of CAP theorem i.e. consistent, available and partition tolerant. To achive the desired benefits of microservices the eventual consitency is implemented via</p>\n<ul>\n<li>\n<p>Event sourcing - We can query an application’s state to find out the current state of the world, and this answers many questions. However there are times when we don’t just want to see where we are, we also want to know how we got there.\nEvent Sourcing ensures that all changes to application state are stored as a sequence of events. Not just can we query these events, we can also use the event log to reconstruct past states, and as a foundation to automatically adjust the state to cope with retroactive changes. e.g. database event logs, similar implementation can be adopted for business events and each micro services can perform action independently to bring system to desired state eventually.</p>\n</li>\n<li>\n<p>CQRS - CQRS stands for Command Query Responsibility Segregation. It’s a pattern that I first heard described by Greg Young. At its heart is the notion that you can use a different model to update information than the model you use to read information. The micro service can process data and keep upto date information for serving realtime need but can update the core system from log. e.g. a notification for ecommerce order placement can be serverd seperately to updates in erp system.</p>\n</li>\n<li>\n<p>Message/Service Bus - For event based message passing in microservice either a direct call to the service can be initited or a message broker such as service bus can be implemented for asyncronous communication maintaining the high demand services to scale to serve client needs and keeping background jobs instance low.</p>\n</li>\n</ul>\n<p>The above eventual consitency also require cordination of execution. The solution is defined as saga. Implement each business transaction that spans multiple services as a saga. A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.</p>\n<p>There are two ways of coordination sagas:</p>\n<ul>\n<li>Choreography - each local transaction publishes domain events that trigger local transactions in other services</li>\n<li>Orchestration - an orchestrator (object) tells the participants what local transactions to execute</li>\n</ul>\n<p><strong>Law of scalable deployment</strong></p>\n<p>Easy deployment and scalability is the key feature that bought microservices into architects tool box. There are various containerisation frameworks/application that can compile into deployable image that is ready to scale. Application containerization is an OS-level virtualization method used to deploy and run distributed applications without launching an entire virtual machine (VM) for each app. Multiple isolated applications or services run on a single host and access the same OS kernel. Application containers include the runtime components — such as files, environment variables and libraries — necessary to run the desired software. Application containers consume fewer resources than a comparable deployment on virtual machines because containers share resources without a full operating system to underpin each app.</p>\n<p>The most common app containerization technology is Docker, specifically the open source Docker Engine and containerd based on universal runtime runC. The main competitive offering is CoreOS’ rkt container engine that relies on the App Container (appc) spec as its open, standard container format, but it also can execute Docker container images.</p>\n<p>Though containerisation is not required to develop and run microservices but these two concepts have be tied together as complementary services to generate maximum benefit. The recommended practice is to deploy services using orchestrator such as Azure Kubernetes services, AWS fargate where that can create a instance for public or private registry such as docker hub, Azure container service etc. You can deploy multiple container on one host or have one host per container.</p>\n<p>Now Azure app service has capability to run docker image but usually with orchestrators in place, a clusture such as docker swarm, azure service fabric, azure service fabric mesh is usually used as deployment engine.</p>\n<p>Since these dynamic addition or removal of images may result is multiple end points thus a service discover provider is required to let the traffic routed to healthy end points only.</p>\n<p><strong>Law of green initiation</strong></p>\n<p>When working on a green field project multiple design pattern help us structure the </p>\n<p><strong>Law of brown transition</strong></p>\n<p><strong>Law of implementation patterns</strong></p>\n<p><strong>Law of communication</strong></p>\n<p><strong>Law of Monitoring</strong></p>","frontmatter":{"date":"January 28, 2019","title":"9 laws of architecting microservices"}}},{"node":{"id":"83fca52e-f506-543b-bb37-b7d9695f772c","excerpt":"A concurrent program has multiple logical threads of control. These threads may or may not run in parallel. A parallel program potentially…","fields":{"slug":"/2019-01-04-elixir-concurrency-models/"},"html":"<p>A concurrent program has multiple logical threads of control. These threads may or may not run in parallel. A parallel program potentially runs more quickly than a sequential program by executing different parts of the computation simultaneously (in parallel). It may or may not have more than one logical thread of control. An alternative way of thinking about this is that concurrency is an aspect of the problem domain—your program needs to handle multiple simultaneous (or near-simultaneous) events. Parallelism, by contrast, is an aspect of the solution domain—you want to make your program faster by processing different portions of the problem in parallel.</p>\n<p>Functional programming avoids the problems associated with a shared mutable state by avoiding mutable state. Actor programming, by contrast, retains mutable state but avoids sharing it. An actor is like an object in an object-oriented (OO) program—it encapsulates state and communicates with other actors by exchanging messages. The difference is that actors run concurrently with each other and, unlike OO-style message passing (which is really just calling a method), actors really communicate by sending messages to each other.</p>\n<p>Certainly, there are some concurrent programs that will always be non-deterministic. And this is unavoidable—some problems require solutions that are intrinsically dependent on the details of timing. But it’s not the case that all parallel programs are necessarily non-deterministic. The value of the sum of the numbers between 0 and 10,000 won’t change just because we add those numbers together in parallel instead of sequentially</p>\n<p>Microsoft <a href=\"https://dotnet.github.io/orleans/\">Orleans</a> is .net implementation of Actor Model but we will focus on programming language which was built with a focus on concurrent execution. Elixir/Erlang: Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability. Some of its uses are in telecoms, banking, e-commerce, computer telephony and instant messaging. Erlang’s runtime system has built-in support for concurrency, distribution and fault tolerance.\nOTP is a set of Erlang libraries and design principles providing middle-ware to develop these systems. It includes its own distributed database, applications to interface towards other languages, debugging and release handling tools. Erlang runs on VM called BEAM which is essentially a <a href=\"https://en.wikipedia.org/wiki/Virtual_machine\">process virtual machine</a></p>\n<blockquote>\n<p>In Erlang, and therefore Elixir, an actor is called a process. In most environments, a process is a heavyweight entity that consumes lots of resources and is expensive to create. An Elixir process, by contrast, is very lightweight—lighter weight even than most systems’ threads, both in terms of resource consumption and startup cost. Elixir programs typically create thousands of processes without problems and don’t normally need to resort to the equivalent of thread pools</p>\n</blockquote>\n<p><strong>Elixir actor by example</strong>  </p>\n<p>Elixir actors communicate via message passing using mailboxes, which are queues by data structure. For our example, we will create a md5 hash generator which based on a string return a md5 value of a string. If the value is already exiting it will not recompute to save CPU resource but send it from in-memory cache.</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt; IO.puts(&quot;#{value}&quot;)</code> will replace #{value} with computed hash function<br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">pid = spawn(&amp;HashIt.loop/0)</code><br>\n<code class=\"language-text\">send(pid, {:compute, &quot;bipin&quot;})</code><br>\n<code class=\"language-text\">sleep(1000)</code>  </p>\n<p>This function implements an infinite loop by calling itself recursively. The receive block waits for a message and then uses pattern matching to work out how to handle it.  Elixir implements tail-call elimination. Tail-call elimination, as its name suggests, replaces a recursive call with a simple jump if the last thing the function does is call itself, thus infinite recursive call o loop function will not result in stack overflow.</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt; IO.puts(:crypto.hash(:md5, value) |&gt; Base.encode16())</code><br>\n           <code class=\"language-text\">{:shutdown} -&gt;  -&gt; exit(:normal)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">receive do</code><br>\n   <code class=\"language-text\">{:EXIT, ^pid, reason} -&gt; IO.puts(&quot;HasIt has exited (#{reason})&quot;)</code><br>\n<code class=\"language-text\">end</code></p>\n<p><code class=\"language-text\">Process.flag(:trap_exit, true)</code><br>\n<code class=\"language-text\">pid = spawn_link(&amp;HashIt.loop/0)</code><br>\n<code class=\"language-text\">send(pid, {:compute, &quot;bipin&quot;})</code><br>\n<code class=\"language-text\">send(pid, {:shutdown}</code>  </p>\n<p><strong>Adding state to the actor</strong>  </p>\n<p>We will add a variable to store all values sent and their computed hash</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop(strg) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt;</code><br>\n               <code class=\"language-text\">hashValue = :crypto.hash(:md5 , value) |&gt; Base.encode16()</code><br>\n               <code class=\"language-text\">updatedStrg = strg.put(strg, value, hashValue)</code><br>\n               <code class=\"language-text\">IO.puts(hashValue)</code><br>\n               <code class=\"language-text\">loop(updatedStrg)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p>Here Strg is an elixir Map and we can start the process by using  </p>\n<p><code class=\"language-text\">pid = spawn(HashIt, :loop, [%{}])</code>  </p>\n<p>or we can define methods to start, compute also provide it a name instead of using pid by registering it.  </p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def start(name, strg, cryptoType) do</code><br>\n       <code class=\"language-text\">pid = spawn(__MODULE__, :loop, [strg, cryptoType])</code><br>\n       <code class=\"language-text\">Process.register(pid, name)</code><br>\n       <code class=\"language-text\">pid</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def compute(name, value) do</code><br>\n       <code class=\"language-text\">ref = make_ref()</code><br>\n       <code class=\"language-text\">send(name, {:compute, value, self(), ref})</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:ok, ^ref, reply} -&gt; reply</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop(strg, cryptoType) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value, sender, ref} -&gt;</code><br>\n               <code class=\"language-text\">hashValue = :crypto.hash(cryptoType , value) |&gt; Base.encode16()</code><br>\n               <code class=\"language-text\">updatedStrg = Map.put_new(strg, value, hashValue)</code><br>\n               <code class=\"language-text\">send(sender, {:ok, ref, hashValue})</code><br>\n               <code class=\"language-text\">loop(updatedStrg, cryptoType)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p>The program can be started via start method and uses pseudo-variable <strong>MODULE</strong>, which evaluates to the name of the current module. The Process.register registers the pid as name :hashit. Moreover, instead of printing the hash value it now returns it to the sender, which helps in bi-directional communication. The carot ^ symbol in {:ok, ^ref, reply} denotes we want to match the value rather than binding it. The <a href=\"https://elixir-lang.org/getting-started/pattern-matching.html\">pattern matching</a> in elixir is used to match inside a data structure. Effectively we can now execute the HashIt module via</p>\n<p><code class=\"language-text\">:hashItMD5 |&gt; HashIt.start([%{}, :md5])</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; HashIt.compute(&quot;bipin&quot;)</code></p>\n<p><strong>Adding check and compute logic</strong>  </p>\n<p>Adding the return value to check in the cache before recomputing above module can be refactored as</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def start(name, strg, cryptoType) do</code><br>\n       <code class=\"language-text\">pid = spawn(__MODULE__, :loop, [strg, cryptoType])</code><br>\n       <code class=\"language-text\">Process.register(pid, name)</code><br>\n       <code class=\"language-text\">pid</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def compute(name, value) do</code><br>\n       <code class=\"language-text\">ref = make_ref()</code><br>\n       <code class=\"language-text\">send(name, {:compute, value, self(), ref})</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:ok, ^ref, reply} -&gt; reply</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop(strg, cryptoType) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value, sender, ref} -&gt;</code><br>\n               <code class=\"language-text\">result = Map.fetch(strg, value)</code><br>\n               <code class=\"language-text\">case result do</code><br>\n                   <code class=\"language-text\">{:ok, val} -&gt; send(sender, {:ok, ref, val})</code><br>\n                        <code class=\"language-text\">loop(strg, cryptoType)</code><br>\n                   <code class=\"language-text\">{:error, _reason} -&gt;</code><br>\n                        <code class=\"language-text\">hashValue = :crypto.hash(cryptoType , value) |&gt; Base.encode16()</code><br>\n                        <code class=\"language-text\">updatedStrg = Map.put_new(strg, value, hashValue)</code><br>\n                        <code class=\"language-text\">send(sender, {:ok, ref, hashValue})</code><br>\n                        <code class=\"language-text\">loop(updatedStrg, cryptoType)</code><br>\n               <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p><strong>Making it fault tolerant</strong>  </p>\n<p>Thus various processes can be started in parallel for different crypto compute example MD5, SHA128, SHA256. Using the above process mechanism we can create multiple processes for different or same task resulting in both concurrent and parallel deterministic outputs. But this architecture does not provide fault tolerance. What if there is an error and it is aborted abruptly? Elixir provides a mechanism to link it to a process which is bi-directional.  </p>\n<p><code class=\"language-text\">:hashItMD5 |&gt; HashIt.start([%{}, :md5])</code><br>\n<code class=\"language-text\">:hashItSHA256 |&gt; HashIt.start([%{}, :sha256])</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; Process.link(:hashItSHA256)</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; exit(:forced_kill)</code>  </p>\n<p>Since we are using spawn in our hash, We can also use spawn_link method to link process instead of process.link(). Please note links created are bi directional. and calling abnormal exit on :hashItMD5 will also set :hashItSHA256 to nil  </p>\n<p><code class=\"language-text\">Process.info(:hashItMD5, :status)</code><br>\n<small>nil</small><br>\n<code class=\"language-text\">Process.info(:hashItSHA256, :status)</code><br>\n<small>nil</small>  </p>\n<p>but normal exit will keep the linked process active, viz:<br>\n<code class=\"language-text\">:hashItMD5 |&gt; exit(:normal)</code><br>\n<code class=\"language-text\">Process.info(:hashItMD5, :status)</code><br>\n<small>nil</small><br>\n<code class=\"language-text\">Process.info(:hashItSHA256, :status)</code><br>\n<small>{:status, :waiting}</small>  </p>\n<p>This implies we can set the system trap to capture other processes exit, when can be utilized to create supervisor and restart the system if the process crashes. We can set Process.flag(:trap_exit, true) to capture the exit of linked process and take appropriate action. In our example of HashIt, a supervisor can be created as:  </p>\n<p><code class=\"language-text\">defmodule HashItSupervisor do</code><br>\n   <code class=\"language-text\">def start do</code><br>\n       <code class=\"language-text\">spawn(__MODULE__, :loop_system,[])</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop_system do</code><br>\n       <code class=\"language-text\">Process.flag(:trap_exit, true)</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">pid = HashIt.start(%{}, :md5)</code> // instead of using spawn please change it to spawn_link in HashIt module<br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:EXIT, ^pid, :normal} -&gt; IO.puts(&quot;Hash It exited normally&quot;)</code><br>\n               <code class=\"language-text\">:ok</code><br>\n           <code class=\"language-text\">{:EXIT, ^pid, reason} -&gt; IO.puts(&quot;Hash It failed with reason #{inspect reason}...restarting&quot;)</code><br>\n               <code class=\"language-text\">loop</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">HashItSupervisor.start</code>  </p>\n<p>If the HashIt system now crashes it is captured by HashItSupervisor and is restarted. If the two processes are dependent on each other and can result in deadlock or infinite waiting because of crashing of sender the receiver can be guarded using timeout clause in receive do loop by using after clause. example:</p>\n<p><code class=\"language-text\">receive do</code><br>\n   <code class=\"language-text\">{:ok, ^ref, value} -&gt; IO.puts(value)</code><br>\n   <code class=\"language-text\">after 1000 -&gt; nil</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p><strong>Scaling to multiple nodes/computers</strong>  </p>\n<p>The actor programming naturally supports an approach to writing fault-tolerant code that leverages this observation: the error-kernel pattern. In the elixir system, the kernel is the root supervisor which can start other supervisors or workers. When we create an elixir virtual machine we create a node we can create nodes multiple nodes on the same system or on network of computer by naming them using —name or —sname option. To make multiple nodes part of the same cluster it must use same —cookie name argument. This results in running your system across multiple systems. To multiple connect nodes we can use connect function</p>\n<p><code class=\"language-text\">iex(node1@192.168.0.10)1&gt; Node.self</code><br>\n<small>:“node1@192.168.0.10”</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)2&gt; Node.list</code><br>\n<small>[]</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)3&gt; Node.connect(:&quot;node2@192.168.0.20&quot;)</code><br>\n<small>true</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)4&gt; Node.list</code><br>\n<small>[:“node2@192.168.0.20”]</small>  </p>\n<p>Now use Node.Spwan to start worker or supervisors and use :global.register_name() instead of Process.register() to make names cluster global. </p>\n<p><strong>Important notes</strong>  </p>\n<p>For this explanatory purpose, we used dynamic atom naming above. However, naming dynamic processes with atoms is a terrible idea! If we use atoms, we would need to convert the name (often received from an external client) to atoms, and we should never convert user input to atoms. This is because atoms are not garbage collected. Once an atom is created, it is never reclaimed. Generating atoms from user input would mean the user can inject enough different names to exhaust our system memory!  </p>\n<p>In practice, it is more likely you will reach the Erlang VM limit for the maximum number of atoms before you run out of memory, which will bring your system down regardless. Moreover, supervisor model used above can result in inconsistent naming convention across various modules and libraries. Thus elixir provides a standard protocol for defining, starting and maintaining workers using efficient bucketed methodology using <a href=\"https://elixir-lang.org/getting-started/mix-otp/genserver.html\">GenServer</a>, providing standard call, cast and info method implementation for various operation.</p>","frontmatter":{"date":"January 04, 2019","title":"phoenix/elixir - concurrency actor model with 'let it crash' philosophy"}}}]}},"pageContext":{"tag":"technology"}}
{"data":{"site":{"siteMetadata":{"title":"paul blog","description":"thoughts, stories & ideas.","author":"Bipin Paul Bedi","siteUrl":"https://www.bipinpaulbedi.com"}},"allMarkdownRemark":{"totalCount":5,"edges":[{"node":{"id":"ed3d1d43-7c2b-57f8-b309-3f5b110c3ecb","excerpt":"Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes decision around…","fields":{"slug":"/2019-01-28-microservices-design-pattern/"},"html":"<p>Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes decision around maintainability and implementation of microservices. The evanglists behind microservice approach have built the case around speed, scalability and cohesion stating in that a microservice Change is easy, Units are small, scalability is semi infinite. So what is Microservice architecture? Microservices — also known as the microservice architecture — is an architectural style that structures an application as a collection of loosely coupled services, which implement business capabilities.</p>\n<p>We will discuss and summarize some of the implementation factors that have big impact on indicators of success in your project/software delivery viz:</p>\n<p><strong>Law of repository management</strong></p>\n<p>One of the most active moving part of micro services is code repositories. They can be categorised into two broader areas.</p>\n<ul>\n<li>Mono Repository i.e. keep all the services in the same repository</li>\n<li>Multiple Repositories i.e. keep separate repositories for each of the services</li>\n</ul>\n<p>Majority of microservices evolve over a period of time and it has been observed that based on team and organisation stucutures derives the strategy adobted for code management. Usually it naturally tends towards multiple repository pattern due of diverse practices followed in an organization among various units. This results in poor code reusabiliy but also provides clear boundaries of ownership. The problem of reusability can be resolve by implementing re-usable package, e.g. nugets for .net or npm for node etc. As the number of services grows it becomes difficult to debug and cross teams development. Moreover overall platform knowledge becomes fragmented and abstract due to focused development teams.</p>\n<p>For a larger project it is recomended to use Mono repository with clear segrigation of domin functionality and shared core reusability. This brings standardisation is development style and practices. It provides better integration capabilities and debugging at the cost of larger code base. Most programming framework provides modular development approach where we can leverage best of both world of mono repo for development and multi repo for build and release.</p>\n<p><strong>Law of seperation of concern</strong></p>\n<p>The most common dilemma that microservice bring into an architects plate is regarding granuality of functionality. As per recomended practice the domain driven development leads to correct size of bounded context which is articulated based on various business activities and influence. Usually, in real world it has been noticed that business units and generated based on software boundaries. Nevertheless using microservices does not implies less code, rather it focus on maintainablity and scalability. If you are planning to create a microservice for each functionality then it is definately planning for diaster. Majority of seggrigation shall be based on domain but under special scenarios it is absoluty deviate and create a seperate service based on technical feature, e.g. email service, notification service etc.</p>\n<p>The mutual independence across multiple microservices is te core principle behind this architecture. Each service shall ideally implement its own data persistence and caching capabilities. The owner service defines the strategy to create, manipulate and consume service. The external services should not be entertaining data access directly but shall only pass through owner service interfaces only.</p>\n<p>The cross cutting concers such as authentication shall be abstracted to gateways such as azure api management, <a href=\"http://threemammals.com/ocelot\">ocelot</a>. In certain senarios a aggregator microservice might be required from client or as a server rapper to avoid multiple dependenct hell.</p>\n<p><strong>Law of eventual consistency</strong></p>\n<p>Since each service is responsible for consistency and reliabiliy of its data the cross domain data passing is performed via message passing. It does not result in ACID [atomic, consitent, isolated, durable] principles as these updates are not happening in transaction. This is can be solved using two phase commit but will eventually result in high coupling and the core principle of microservices are violated. The microservice arctchitecture is an advocate of CAP theorem i.e. consistent, available and partition tolerant. To achive the desired benefits of microservices the eventual consitency is implemented via</p>\n<ul>\n<li>\n<p>Event sourcing - We can query an application’s state to find out the current state of the world, and this answers many questions. However there are times when we don’t just want to see where we are, we also want to know how we got there.\nEvent Sourcing ensures that all changes to application state are stored as a sequence of events. Not just can we query these events, we can also use the event log to reconstruct past states, and as a foundation to automatically adjust the state to cope with retroactive changes. e.g. database event logs, similar implementation can be adopted for business events and each micro services can perform action independently to bring system to desired state eventually.</p>\n</li>\n<li>\n<p>CQRS - CQRS stands for Command Query Responsibility Segregation. It’s a pattern that I first heard described by Greg Young. At its heart is the notion that you can use a different model to update information than the model you use to read information. The micro service can process data and keep upto date information for serving realtime need but can update the core system from log. e.g. a notification for ecommerce order placement can be serverd seperately to updates in erp system.</p>\n</li>\n<li>\n<p>Message/Service Bus - For event based message passing in microservice either a direct call to the service can be initited or a message broker such as service bus can be implemented for asyncronous communication maintaining the high demand services to scale to serve client needs and keeping background jobs instance low.</p>\n</li>\n</ul>\n<p>The above eventual consitency also require cordination of execution. The solution is defined as saga. Implement each business transaction that spans multiple services as a saga. A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.</p>\n<p>There are two ways of coordination sagas:</p>\n<ul>\n<li>Choreography - each local transaction publishes domain events that trigger local transactions in other services</li>\n<li>Orchestration - an orchestrator (object) tells the participants what local transactions to execute</li>\n</ul>\n<p><strong>Law of scalable deployment</strong></p>\n<p>Easy deployment and scalability is the key feature that bought microservices into architects tool box. There are various containerisation frameworks/application that can compile into deployable image that is ready to scale. Application containerization is an OS-level virtualization method used to deploy and run distributed applications without launching an entire virtual machine (VM) for each app. Multiple isolated applications or services run on a single host and access the same OS kernel. Application containers include the runtime components — such as files, environment variables and libraries — necessary to run the desired software. Application containers consume fewer resources than a comparable deployment on virtual machines because containers share resources without a full operating system to underpin each app.</p>\n<p>The most common app containerization technology is Docker, specifically the open source Docker Engine and containerd based on universal runtime runC. The main competitive offering is CoreOS’ rkt container engine that relies on the App Container (appc) spec as its open, standard container format, but it also can execute Docker container images.</p>\n<p>Though containerisation is not required to develop and run microservices but these two concepts have be tied together as complementary services to generate maximum benefit. The recommended practice is to deploy services using orchestrator such as Azure Kubernetes services, AWS fargate where that can create a instance for public or private registry such as docker hub, Azure container service etc. You can deploy multiple container on one host or have one host per container.</p>\n<p>Now Azure app service has capability to run docker image but usually with orchestrators in place, a clusture such as docker swarm, azure service fabric, azure service fabric mesh is usually used as deployment engine.</p>\n<p>Since these dynamic addition or removal of images may result is multiple end points thus a service discover provider is required to let the traffic routed to healthy end points only.</p>\n<p><strong>Law of green initiation</strong></p>\n<p>When working on a green field project</p>\n<p><strong>Law of brown transition</strong></p>\n<p><strong>Law of implementation patterns</strong></p>\n<p><strong>Law of communication</strong></p>\n<p><strong>Law of Monitoring</strong></p>","frontmatter":{"date":"January 28, 2019","title":"9 laws of architecting microservices"}}},{"node":{"id":"83fca52e-f506-543b-bb37-b7d9695f772c","excerpt":"A concurrent program has multiple logical threads of control. These threads may or may not run in parallel. A parallel program potentially…","fields":{"slug":"/2019-01-04-elixir-concurrency-models/"},"html":"<p>A concurrent program has multiple logical threads of control. These threads may or may not run in parallel. A parallel program potentially runs more quickly than a sequential program by executing different parts of the computation simultaneously (in parallel). It may or may not have more than one logical thread of control. An alternative way of thinking about this is that concurrency is an aspect of the problem domain—your program needs to handle multiple simultaneous (or near-simultaneous) events. Parallelism, by contrast, is an aspect of the solution domain—you want to make your program faster by processing different portions of the problem in parallel.</p>\n<p>Functional programming avoids the problems associated with a shared mutable state by avoiding mutable state. Actor programming, by contrast, retains mutable state but avoids sharing it. An actor is like an object in an object-oriented (OO) program—it encapsulates state and communicates with other actors by exchanging messages. The difference is that actors run concurrently with each other and, unlike OO-style message passing (which is really just calling a method), actors really communicate by sending messages to each other.</p>\n<p>Certainly, there are some concurrent programs that will always be non-deterministic. And this is unavoidable—some problems require solutions that are intrinsically dependent on the details of timing. But it’s not the case that all parallel programs are necessarily non-deterministic. The value of the sum of the numbers between 0 and 10,000 won’t change just because we add those numbers together in parallel instead of sequentially</p>\n<p>Microsoft <a href=\"https://dotnet.github.io/orleans/\">Orleans</a> is .net implementation of Actor Model but we will focus on programming language which was built with a focus on concurrent execution. Elixir/Erlang: Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability. Some of its uses are in telecoms, banking, e-commerce, computer telephony and instant messaging. Erlang’s runtime system has built-in support for concurrency, distribution and fault tolerance.\nOTP is a set of Erlang libraries and design principles providing middle-ware to develop these systems. It includes its own distributed database, applications to interface towards other languages, debugging and release handling tools. Erlang runs on VM called BEAM which is essentially a <a href=\"https://en.wikipedia.org/wiki/Virtual_machine\">process virtual machine</a></p>\n<blockquote>\n<p>In Erlang, and therefore Elixir, an actor is called a process. In most environments, a process is a heavyweight entity that consumes lots of resources and is expensive to create. An Elixir process, by contrast, is very lightweight—lighter weight even than most systems’ threads, both in terms of resource consumption and startup cost. Elixir programs typically create thousands of processes without problems and don’t normally need to resort to the equivalent of thread pools</p>\n</blockquote>\n<p><strong>Elixir actor by example</strong>  </p>\n<p>Elixir actors communicate via message passing using mailboxes, which are queues by data structure. For our example, we will create a md5 hash generator which based on a string return a md5 value of a string. If the value is already exiting it will not recompute to save CPU resource but send it from in-memory cache.</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt; IO.puts(&quot;#{value}&quot;)</code> will replace #{value} with computed hash function<br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">pid = spawn(&amp;HashIt.loop/0)</code><br>\n<code class=\"language-text\">send(pid, {:compute, &quot;bipin&quot;})</code><br>\n<code class=\"language-text\">sleep(1000)</code>  </p>\n<p>This function implements an infinite loop by calling itself recursively. The receive block waits for a message and then uses pattern matching to work out how to handle it.  Elixir implements tail-call elimination. Tail-call elimination, as its name suggests, replaces a recursive call with a simple jump if the last thing the function does is call itself, thus infinite recursive call o loop function will not result in stack overflow.</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt; IO.puts(:crypto.hash(:md5, value) |&gt; Base.encode16())</code><br>\n           <code class=\"language-text\">{:shutdown} -&gt;  -&gt; exit(:normal)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">receive do</code><br>\n   <code class=\"language-text\">{:EXIT, ^pid, reason} -&gt; IO.puts(&quot;HasIt has exited (#{reason})&quot;)</code><br>\n<code class=\"language-text\">end</code></p>\n<p><code class=\"language-text\">Process.flag(:trap_exit, true)</code><br>\n<code class=\"language-text\">pid = spawn_link(&amp;HashIt.loop/0)</code><br>\n<code class=\"language-text\">send(pid, {:compute, &quot;bipin&quot;})</code><br>\n<code class=\"language-text\">send(pid, {:shutdown}</code>  </p>\n<p><strong>Adding state to the actor</strong>  </p>\n<p>We will add a variable to store all values sent and their computed hash</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop(strg) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt;</code><br>\n               <code class=\"language-text\">hashValue = :crypto.hash(:md5 , value) |&gt; Base.encode16()</code><br>\n               <code class=\"language-text\">updatedStrg = strg.put(strg, value, hashValue)</code><br>\n               <code class=\"language-text\">IO.puts(hashValue)</code><br>\n               <code class=\"language-text\">loop(updatedStrg)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p>Here Strg is an elixir Map and we can start the process by using  </p>\n<p><code class=\"language-text\">pid = spawn(HashIt, :loop, [%{}])</code>  </p>\n<p>or we can define methods to start, compute also provide it a name instead of using pid by registering it.  </p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def start(name, strg, cryptoType) do</code><br>\n       <code class=\"language-text\">pid = spawn(__MODULE__, :loop, [strg, cryptoType])</code><br>\n       <code class=\"language-text\">Process.register(pid, name)</code><br>\n       <code class=\"language-text\">pid</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def compute(name, value) do</code><br>\n       <code class=\"language-text\">ref = make_ref()</code><br>\n       <code class=\"language-text\">send(name, {:compute, value, self(), ref})</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:ok, ^ref, reply} -&gt; reply</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop(strg, cryptoType) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value, sender, ref} -&gt;</code><br>\n               <code class=\"language-text\">hashValue = :crypto.hash(cryptoType , value) |&gt; Base.encode16()</code><br>\n               <code class=\"language-text\">updatedStrg = Map.put_new(strg, value, hashValue)</code><br>\n               <code class=\"language-text\">send(sender, {:ok, ref, hashValue})</code><br>\n               <code class=\"language-text\">loop(updatedStrg, cryptoType)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p>The program can be started via start method and uses pseudo-variable <strong>MODULE</strong>, which evaluates to the name of the current module. The Process.register registers the pid as name :hashit. Moreover, instead of printing the hash value it now returns it to the sender, which helps in bi-directional communication. The carot ^ symbol in {:ok, ^ref, reply} denotes we want to match the value rather than binding it. The <a href=\"https://elixir-lang.org/getting-started/pattern-matching.html\">pattern matching</a> in elixir is used to match inside a data structure. Effectively we can now execute the HashIt module via</p>\n<p><code class=\"language-text\">:hashItMD5 |&gt; HashIt.start([%{}, :md5])</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; HashIt.compute(&quot;bipin&quot;)</code></p>\n<p><strong>Adding check and compute logic</strong>  </p>\n<p>Adding the return value to check in the cache before recomputing above module can be refactored as</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def start(name, strg, cryptoType) do</code><br>\n       <code class=\"language-text\">pid = spawn(__MODULE__, :loop, [strg, cryptoType])</code><br>\n       <code class=\"language-text\">Process.register(pid, name)</code><br>\n       <code class=\"language-text\">pid</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def compute(name, value) do</code><br>\n       <code class=\"language-text\">ref = make_ref()</code><br>\n       <code class=\"language-text\">send(name, {:compute, value, self(), ref})</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:ok, ^ref, reply} -&gt; reply</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop(strg, cryptoType) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value, sender, ref} -&gt;</code><br>\n               <code class=\"language-text\">result = Map.fetch(strg, value)</code><br>\n               <code class=\"language-text\">case result do</code><br>\n                   <code class=\"language-text\">{:ok, val} -&gt; send(sender, {:ok, ref, val})</code><br>\n                        <code class=\"language-text\">loop(strg, cryptoType)</code><br>\n                   <code class=\"language-text\">{:error, _reason} -&gt;</code><br>\n                        <code class=\"language-text\">hashValue = :crypto.hash(cryptoType , value) |&gt; Base.encode16()</code><br>\n                        <code class=\"language-text\">updatedStrg = Map.put_new(strg, value, hashValue)</code><br>\n                        <code class=\"language-text\">send(sender, {:ok, ref, hashValue})</code><br>\n                        <code class=\"language-text\">loop(updatedStrg, cryptoType)</code><br>\n               <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p><strong>Making it fault tolerant</strong>  </p>\n<p>Thus various processes can be started in parallel for different crypto compute example MD5, SHA128, SHA256. Using the above process mechanism we can create multiple processes for different or same task resulting in both concurrent and parallel deterministic outputs. But this architecture does not provide fault tolerance. What if there is an error and it is aborted abruptly? Elixir provides a mechanism to link it to a process which is bi-directional.  </p>\n<p><code class=\"language-text\">:hashItMD5 |&gt; HashIt.start([%{}, :md5])</code><br>\n<code class=\"language-text\">:hashItSHA256 |&gt; HashIt.start([%{}, :sha256])</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; Process.link(:hashItSHA256)</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; exit(:forced_kill)</code>  </p>\n<p>Since we are using spawn in our hash, We can also use spawn_link method to link process instead of process.link(). Please note links created are bi directional. and calling abnormal exit on :hashItMD5 will also set :hashItSHA256 to nil  </p>\n<p><code class=\"language-text\">Process.info(:hashItMD5, :status)</code><br>\n<small>nil</small><br>\n<code class=\"language-text\">Process.info(:hashItSHA256, :status)</code><br>\n<small>nil</small>  </p>\n<p>but normal exit will keep the linked process active, viz:<br>\n<code class=\"language-text\">:hashItMD5 |&gt; exit(:normal)</code><br>\n<code class=\"language-text\">Process.info(:hashItMD5, :status)</code><br>\n<small>nil</small><br>\n<code class=\"language-text\">Process.info(:hashItSHA256, :status)</code><br>\n<small>{:status, :waiting}</small>  </p>\n<p>This implies we can set the system trap to capture other processes exit, when can be utilized to create supervisor and restart the system if the process crashes. We can set Process.flag(:trap_exit, true) to capture the exit of linked process and take appropriate action. In our example of HashIt, a supervisor can be created as:  </p>\n<p><code class=\"language-text\">defmodule HashItSupervisor do</code><br>\n   <code class=\"language-text\">def start do</code><br>\n       <code class=\"language-text\">spawn(__MODULE__, :loop_system,[])</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop_system do</code><br>\n       <code class=\"language-text\">Process.flag(:trap_exit, true)</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">pid = HashIt.start(%{}, :md5)</code> // instead of using spawn please change it to spawn_link in HashIt module<br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:EXIT, ^pid, :normal} -&gt; IO.puts(&quot;Hash It exited normally&quot;)</code><br>\n               <code class=\"language-text\">:ok</code><br>\n           <code class=\"language-text\">{:EXIT, ^pid, reason} -&gt; IO.puts(&quot;Hash It failed with reason #{inspect reason}...restarting&quot;)</code><br>\n               <code class=\"language-text\">loop</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">HashItSupervisor.start</code>  </p>\n<p>If the HashIt system now crashes it is captured by HashItSupervisor and is restarted. If the two processes are dependent on each other and can result in deadlock or infinite waiting because of crashing of sender the receiver can be guarded using timeout clause in receive do loop by using after clause. example:</p>\n<p><code class=\"language-text\">receive do</code><br>\n   <code class=\"language-text\">{:ok, ^ref, value} -&gt; IO.puts(value)</code><br>\n   <code class=\"language-text\">after 1000 -&gt; nil</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p><strong>Scaling to multiple nodes/computers</strong>  </p>\n<p>The actor programming naturally supports an approach to writing fault-tolerant code that leverages this observation: the error-kernel pattern. In the elixir system, the kernel is the root supervisor which can start other supervisors or workers. When we create an elixir virtual machine we create a node we can create nodes multiple nodes on the same system or on network of computer by naming them using —name or —sname option. To make multiple nodes part of the same cluster it must use same —cookie name argument. This results in running your system across multiple systems. To multiple connect nodes we can use connect function</p>\n<p><code class=\"language-text\">iex(node1@192.168.0.10)1&gt; Node.self</code><br>\n<small>:“node1@192.168.0.10”</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)2&gt; Node.list</code><br>\n<small>[]</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)3&gt; Node.connect(:&quot;node2@192.168.0.20&quot;)</code><br>\n<small>true</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)4&gt; Node.list</code><br>\n<small>[:“node2@192.168.0.20”]</small>  </p>\n<p>Now use Node.Spwan to start worker or supervisors and use :global.register_name() instead of Process.register() to make names cluster global. </p>\n<p><strong>Important notes</strong>  </p>\n<p>For this explanatory purpose, we used dynamic atom naming above. However, naming dynamic processes with atoms is a terrible idea! If we use atoms, we would need to convert the name (often received from an external client) to atoms, and we should never convert user input to atoms. This is because atoms are not garbage collected. Once an atom is created, it is never reclaimed. Generating atoms from user input would mean the user can inject enough different names to exhaust our system memory!  </p>\n<p>In practice, it is more likely you will reach the Erlang VM limit for the maximum number of atoms before you run out of memory, which will bring your system down regardless. Moreover, supervisor model used above can result in inconsistent naming convention across various modules and libraries. Thus elixir provides a standard protocol for defining, starting and maintaining workers using efficient bucketed methodology using <a href=\"https://elixir-lang.org/getting-started/mix-otp/genserver.html\">GenServer</a>, providing standard call, cast and info method implementation for various operation.</p>","frontmatter":{"date":"January 04, 2019","title":"phoenix/elixir - concurrency actor model with 'let it crash' philosophy"}}},{"node":{"id":"6c7a3c9e-c426-5c72-adf4-29466a385e72","excerpt":"The asymptotic notation is the mathematical representation to analyze algorithm and represent its time (and/or space) complexity as its…","fields":{"slug":"/2018-10-20-asymtotic-notations/"},"html":"<p>The asymptotic notation is the mathematical representation to analyze algorithm and represent its time (and/or space) complexity as its relation to input size. It describes its behavioral characteristics as the input size for the algorithm increases. The algorithm complexity can also be measured by monitoring time and space usage during its actual physical execution. This approach is not ideal for the following reasons  </p>\n<p>The accuracy and relativity (times obtained would only be relative to the machine they were computed on) of this method is bound to environmental variables such as computer hardware specifications, processing power, etc.<br>\nTo conclude a general behavior we would have to execute it in several different scenarios.  </p>\n<p>Thus by representing an algorithm using asymptotic notation, it is much easier, faster and standard methodology to analyze and compare algorithms. For this post, we will restrict our discussion to time complexities {since the tremendous technological advancement has led to the cost of storage (persistent or ephemeral) as negligible}. In any problem domain, for a given algorithm f, with input size n we calculate some resultant runtime f(n). This results in a graph where the Y-axis is the runtime, X-axis is the input size, and plot points are the resultants of the amount of time for a given input size. We would mostly measure the worst-case scenario for any algorithm to compare different algorithms against the standard set of facts and dimentions.  </p>\n<p>Before analysing the algorithms, we shall establish certain common complexity classes in which an algorithm can be classified i.e. g(n) viz. K (or constant), log n, n, n*log n, n^2, n^3…, 2^n, 3^n…n^n  </p>\n<p><strong>Types of Asymptotic Notation</strong>  </p>\n<p><strong>Big-O</strong><br>\nBig-O, commonly written as O, is an Asymptotic Notation for the worst case, or ceiling of growth for a given function. It provides us with an asymptotic upper bound for the growth rate of the runtime of an algorithm.<br>\nFor e.g. f(n) is your algorithm runtime, and g(n) is an arbitrary time complexity you are trying to relate to your algorithm. f(n) is O(g(n)), if for some real constants c (c > 0) and n0, f(n) &#x3C;= c g(n) for every input size n (n > n0)  </p>\n<p><code class=\"language-text\">f(n) = O(g(n) For K and N0</code><br>\n<code class=\"language-text\">if f(n) &lt;= k * g(n) where n&gt;=n0</code><br>\n<code class=\"language-text\">e.g.</code><br>\n<code class=\"language-text\">f(n) = 2n^2 + 3n + 1</code>\n<code class=\"language-text\">since 2n^2 + 3n^2 + n2 = 6n^2</code><br>\n<code class=\"language-text\">f(n) = 2n^2 + 3n + 1 &lt;= 6n^2 for n &gt;= ?</code><br>\n<code class=\"language-text\">f(n) &lt;= k * g(n)</code><br>\n<code class=\"language-text\">i.e. 6 * n^2</code><br>\n<code class=\"language-text\">Thus f(n) = O(n^2)</code></p>\n<p><strong>Big-Omega</strong><br>\nBig-Omega, commonly written as Ω, is an Asymptotic Notation for the best case, or a floor growth rate for a given function. It provides us with an asymptotic lower bound for the growth rate of the runtime of an algorithm.<br>\nf(n) is Ω(g(n)), if for some real constants c (c > 0) and n0 (n0 > 0), f(n) is >= c g(n) for every input size n (n > n0).  </p>\n<p><code class=\"language-text\">f(n) = BIG-OMEGA(g(n) For K and N0</code><br>\n<code class=\"language-text\">if f(n) &gt;= k * g(n) where n&gt;=n0</code><br>\n<code class=\"language-text\">e.g.</code><br>\n<code class=\"language-text\">f(n) = 2n^2 + 3n + 1</code>\n<code class=\"language-text\">f(n) = 2n^2 + 3n + 1 &gt;= n^2 for n &gt;= ?</code><br>\n<code class=\"language-text\">f(n) &lt;= k * g(n)</code><br>\n<code class=\"language-text\">i.e. 1 * n^2</code><br>\n<code class=\"language-text\">or k * g(n)</code><br>\n<code class=\"language-text\">Thus f(n) = BIG-OMEGA(n^2)</code></p>\n<p><strong>Theta</strong><br>\nTheta, commonly written as Θ, is an Asymptotic Notation to denote the asymptotically tight bound on the growth rate of the runtime of an algorithm.<br>\ni.e. if O(g(n)) = Ω(g(n))<br>\nThen<br>\nf(n) = Θ(g(n))</p>\n<p><code class=\"language-text\">If f(n) = O(n2)</code><br>\n<code class=\"language-text\">and f(n) = BIG-OMEGA(n^2)</code><br>\n<code class=\"language-text\">also</code><br>\n<code class=\"language-text\">f(n) = O(g(n)) and f(n) = BIG-OMEGA(g(n))</code>\n<code class=\"language-text\">Then f(n) = THETA(g(n))</code><br>\n<code class=\"language-text\">Thus f(n) = THETA(n^2)</code></p>\n<p>Note\nThe asymptotic growth rates provided by big-O and big-omega notation may or may not be asymptotically tight. Thus we use small-o and small-omega notation to denote bounds that are not asymptotically tight.</p>\n<p>The main difference is that in f(n) = O(g(n)), the bound f(n) &#x3C;= g(n) holds for <strong>some</strong> constant c > 0, but in f(n) = o(g(n)), the bound f(n) &#x3C; c g(n) holds for <strong>all</strong> constants c > 0.\nSimilarly\nf(n) = Ω(g(n)), the bound f(n) >= g(n) holds for <strong>some</strong> constant c > 0, but in f(n) = ω(g(n)), the bound f(n) > c g(n) holds for <strong>all</strong> constants c > 0.</p>\n<p><code class=\"language-text\">Calculating for n!</code><br>\n<code class=\"language-text\">if f(n) = n!</code><br>\n<code class=\"language-text\">f(n) = n * (n-1) * (n-2)... 2 * 1</code>\n<code class=\"language-text\">For upper bound = n * n * n * n * n * n * n</code><br>\n<code class=\"language-text\">i.e. f(n) = n! &lt;= n^n for n&gt;=?</code><br>\n<code class=\"language-text\">f(n) = O(n^n)</code>\n<code class=\"language-text\">For lower bound = 1 * 1 * 1 * 1 * 1...1</code>\n<code class=\"language-text\">= k</code>\n<code class=\"language-text\">Thus f(n) =  BIG-OMEGA(1) or BIG-OMEGA(K)</code><br>\n<code class=\"language-text\">since O and BIG-OMEGA for n! is not equal it does not have a tight bound</code> </p>","frontmatter":{"date":"October 20, 2018","title":"ELI5 - Asymptotic computational complexity simplified"}}},{"node":{"id":"d6824ac9-1d20-5831-9ad4-fdb5848efabb","excerpt":"The most difficult and time consuming activity in any machine learning project is modelling the domain. The objective of training the model…","fields":{"slug":"/2018-10-12-regularization-for-machine-learning-models/"},"html":"<p>The most difficult and time consuming activity in any machine learning project is modelling the domain. The objective of training the model is to reduce the cost function, which can have direct dependency on feature selection and their representation. The results you achieve is a function of the model features and the weights being selected. Even your framing of the problem and measures you’re using to estimate accuracy play a part. Your results are dependent on many inter-dependent properties</p>\n<blockquote>\n<p>Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.</p>\n</blockquote>\n<p>You can see the dependencies in this definition:</p>\n<ul>\n<li>The performance measures you’ve chosen (RMSE? AUC?)</li>\n<li>The framing of the problem (classification? regression?)</li>\n<li>The predictive models you’re using (SVM?)</li>\n<li>The raw data you have selected and prepared (samples? formatting? cleaning?)</li>\n</ul>\n<p>In order to create less complex model when you have a large number of features in your dataset, some of the Regularization techniques are used to address over-fitting. In general, due to the addition of regularization term, the values of weight matrices decrease because it assumes that a neural network with smaller weight matrices leads to simpler models.</p>\n<p><code class=\"language-text\">Cost function = Loss + Regularization term</code></p>\n<p>L1 and L2 are the most common types of regularization. The key difference between these two is the penalty term</p>\n<p><strong>L1 regularization</strong><br>\nA regression model that uses L1 regularization technique is called Lasso Regression</p>\n<p><code class=\"language-text\">Cost function = Loss + &amp;Lambda;/2m * &amp;Sigma;&amp;#124;weight&amp;#124;</code></p>\n<p>Here, lambda is the regularization parameter. It is the hyperparameter whose value is optimized for better results. if lambda is zero then you can imagine we get back original loss. However, if lambda is very large then it will add too much weight and it will lead to under-fitting.<br>\nIn L1 regularization, we penalize the absolute value of the weights. The weights may be reduced to zero here. Hence, it is very useful when we are trying to compress our model. Otherwise, we usually prefer L2 over it.</p>\n<p><strong>L2 regularization</strong><br>\nA regression model model which uses L2 is called Ridge Regression.</p>\n<p><code class=\"language-text\">Cost function = Loss + &amp;Lambda;/2m * &amp;Sigma;&amp;#124;weight&amp;#124;^2</code></p>\n<p>It adds “squared magnitude” of coefficient as penalty term to the loss function. L2 regularization is also known as weight decay as it forces the weights to decay towards zero (but not exactly zero).</p>\n<p>The key difference between these techniques is that in L1 the less important feature’s coefficient are reduced to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.</p>","frontmatter":{"date":"October 12, 2018","title":"L1 & L2 model regularizations techniques"}}},{"node":{"id":"e0ec1d27-f812-5cad-afe8-e1dc91abf91e","excerpt":"As per Wikipedia, Design thinking is the cognitive process from which design concepts (e.g. ideas for products) emerge. Design thinking is…","fields":{"slug":"/2018-10-10-coding-blueprint-for-pragmatic-rest-api-developers/"},"html":"<p>As per Wikipedia, Design thinking is the cognitive process from which design concepts (e.g. ideas for products) emerge. Design thinking is related to, but is different from problem-solving, decision-making, creativity, sketching and prototyping. During design thinking, the designer’s attention oscillates between their understanding of a problem context and their ideas for a solution. New solution ideas lead to a deeper understanding of the problematic context, which in turn triggers more solution ideas.</p>\n<p>When your focus acts like a pendulum between problem context and the creative solution then you are bound to wear multiple hats. The irony as the developer when designing API is that your clients are other developers.\nOver the past decade after working under some fine mentors the summary of the learning can be stated as “Think of developing API endpoints for a command line interface, possibly it will result in self-understandable, complete solution you are seeking”.</p>\n<p>This post is inspired by eBook published by APIgee highlighting the best practiced for REST design. As an API designer, I have gone through some challenges myself, viz.</p>\n<p><strong>What should be my base URL?</strong></p>\n<p>Keep it short and simple. Try to use nouns and keep verbs out of your base URL. To smartly cover all possible scenario use HTTP verb standard.\nEg.</p>\n<table>\n<thead>\n<tr>\n<th>Resource</th>\n<th align=\"center\">POST</th>\n<th align=\"center\">GET</th>\n<th align=\"center\">PUT</th>\n<th align=\"center\">DELETE</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td align=\"center\">create</td>\n<td align=\"center\">read</td>\n<td align=\"center\">update</td>\n<td align=\"center\">delete</td>\n</tr>\n<tr>\n<td>/users</td>\n<td align=\"center\">create a new user</td>\n<td align=\"center\">list users</td>\n<td align=\"center\">bulk update users</td>\n<td align=\"center\">delete all users</td>\n</tr>\n<tr>\n<td>/users/1234</td>\n<td align=\"center\">error</td>\n<td align=\"center\">show user</td>\n<td align=\"center\">update if exists or error</td>\n<td align=\"center\">delete user</td>\n</tr>\n</tbody>\n</table>\n<p>The point is that developers probably don’t need the chart to understand how the API behaves. They can experiment with and learn the API without the documentation.</p>\n<p><strong>Shall I use plurals or singular nouns?</strong></p>\n<p>The recommended practice is to use plurals since the first API being tested by developers is most probably GET and GET /users to list all users make natural sense. Irrespective whatever you choose, be consistent to avoid confusing your API consumers. Moreover, concrete names are better than abstract ones. Eg. Having an endpoint like /blogs or /videos over abstract names like /items or /contents can help the consumer to identify resources more conveniently.<br>\nYou also want to expose a manageable number of resources. Aim for concrete naming and keep the number of resources between 12 and 24.</p>\n<p><strong>How should the relations and associations be exposed in API?</strong></p>\n<p>Resource always have relationships with other resources. oData standard makes it easier for developers to navigate resource and its association using metadata, it can be also let to exposing your information schema.<br>\nThe recommended practise is to follow ‘resource/identity/resource’ model eg. /users/1234/department. It’s not uncommon to see people string these together making a URL 5 or 6 levels deep. Remember that once you have the primary key for one level, you usually don’t need to include the levels above because you’ve already got your specific object.</p>\n<p><strong>How do we handle the complexity of pagination, partial response, filters etc.?</strong></p>\n<p>Make it simple for developers to use the base URL by putting optional states and attributes behind the query string question mark. E.g. GET /users?name=xxx<br>\nFor pagination request for limit and offset eg. GET /users?limit=50&#x26;offset=100 additionally, request fields to make it precise. Avoid using special characters in the query string. A good API always have defaults for pagination.<br>\nGood example /GET users?fields=name,gender<br>\nBad example /Get users:(name,gender)<br>\nWe also suggest including metadata with each response that is paginated that indicated to the developer the total number of records available. Use JSON-LD/HAL/Collection+JSON/SIREN/JSONAPI.ORG specifications as your starting point and don’t forget to be creative.</p>\n<p><strong>What is the recommended practice for error handling?</strong></p>\n<p>The developers learn to write code through error and trial, most important they rely on error messages during critical times for troubleshooting and resolving issues.<br>\nAs the best practice always serve the error messages with correct HTTP status codes, also include a verbose error message with as many details as possible. We highly recommend that you add a link in your description to add more information.<br>\nIn certain circumstances the framework used by developer intercepts the message and follows the default routine, thus developer may have no opportunity to inform his user appropriately. Thus, if you can provide a flag to suppress the status code and result in HTTP - 200 OK with actual status code and the message passed along with the payload.</p>\n<p><strong>Shall we version control the API?</strong></p>\n<p>Never release an API without a version and make the version mandatory. Keep the version naming simple and maintain compatibility with at least one version backwards for minimum 6-12 months.<br>\nSome developers advocate as to keep the version information in headers. But API can have breaking changes, thus being verbose and explicitly specifying version numbers in URL can help developers identify gaps early.</p>\n<p><strong>What about responses that don’t involve resources?</strong></p>\n<p>In certain cases, API calls that sends a response which is not a resource e.g. Calculate, Translate are not uncommon depending on the domain.\nIn these cases, Use verbs not nouns e.g. /convert?from=USD&#x26;to=AUD&#x26;amount=100<br>\nMake it clear in your API documentation that these “non-resource” scenarios are different, maybe in you swagger docs.<br>\n<br>\n<strong>How many formats shall we support?</strong></p>\n<p>Respect the HTTP header content-type and accepts e.g. Accept: application/json but let the user override using dot notation e.g. GET /user/1234.dat or GET /user/1234.xml<br>\nIf the default form is JSON, in the response properties try using camelCase for attributes as it is easier for the front-end developer to parse into objects with standard JavaScript conventions.</p>\n<p><strong>Any other tips and tricks?</strong></p>\n<p><em>Tip1:</em><br>\nA simple can be verb based resourceful API but for complex scenarios use google model\ne.g.<br>\n/search?q=xxx<br>\n/user?q=xxx<br>\n/location/1234/user=xxx – scoped<br>\n/search.xml?q=xxx – formatted  </p>\n<p><em>Tip2:</em><br>\nConsolidate API under a single domain with segregation for environments following a standard pattern e.g.\napi.xxx.com\nuat-api.xxx.com\ndev-api.xxx.com</p>\n<p><em>Tip3:</em><br>\nUse standard known authentication/authorization methodologies e.g. oAuth2.0 etc</p>\n<p><em>Tip4:</em><br>\nTry to complement your API with SDK</p>\n<p><em>Tip5:</em><br>\nUsing POST to emulate PUT, DELETE, PATCH. If your development platform or firewall rules prevent you from calling HTTP methods like PUT, PATCH or DELETE, use the X-HTTP-Method-Override header. Pass the method you want to use in the X-HTTP-Method-Override header and make your call using the POST method</p>\n<p><strong>What API design pattern is an ideal choice in most cases?</strong></p>\n<p>The architect must carefully evaluate available options and what suits the business domain and skill set of available developers in terms of project support and maintainability. But in most cases, an API Façade with mediate to complement can cover the majority of cases. This is covered in detail in another post.</p>","frontmatter":{"date":"October 10, 2018","title":"Developers guide to designing REST endpoints"}}}]}},"pageContext":{"tag":"article"}}
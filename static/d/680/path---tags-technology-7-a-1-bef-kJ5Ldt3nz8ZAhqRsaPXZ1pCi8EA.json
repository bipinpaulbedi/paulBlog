{"data":{"site":{"siteMetadata":{"title":"paul blog","description":"thoughts, stories & ideas.","author":"Bipin Paul Bedi","siteUrl":"https://www.bipinpaulbedi.com"}},"allMarkdownRemark":{"totalCount":2,"edges":[{"node":{"id":"ed3d1d43-7c2b-57f8-b309-3f5b110c3ecb","excerpt":"Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes to making…","fields":{"slug":"/2019-01-28-microservices-design-pattern/"},"html":"<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9787c4f6a7d8c18e97cc988918fecd57/70d9e/microservices.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 800px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 43.7007874015748%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAAClUlEQVQoz2PIX/eUARtoq8kUAVJcQMwTYyUjGMjIwFuQkyhwaVM1t42FuQgDPnDr93+3////C1kv/GHtcPq/JAODnAkDk5Lzviv3HPYev+RhW7zM0nviiSg2QXUDBkHThNLaBu2Hf/97H9z+n8117X9vBq8VQIv1PBgYpIQYpt74P2fm3vvPNHc+3mO25fetLc/+H0ytnXvVp3nHkfXX/p2I3H77otD2X0e6L/+/PHf7xV2WSRNvzLv+f3PnzptPWHe83RK75//zfQ/+7nZO6XnGvvDqLgazkmWXmTUibyhMvvao5OL/a5GzLz2YevT1ncatt+5xmabd546ffS/q/P+H+Wsf3sxbdfPJyssfr2glTnrOoJNw2XL3/+e1h39cDZ1x7sWaa18vabRtvs3AYJh4lskm65Z24forYmHdVxkcq24zudXeYrLOuMlgGH9DPmHGTY3sZZcY7ItvMzjV3WBzyLvJYJR4k8O1/KZe2bYbbC5ltxgcaq+zOZfcZDVPO8XAYF/4XyWm679MUM1/Bpv8/0oRzf91Err+83pW/WdyKv2vENb4XyOm5T+PR+V/Tpfi/9qJPf814jr/MzuX/pfwq/ivGNkGFC/6rxjV8V8RqJeBwTo7l90xP5vduTiHwTonh8E2P0vUo6CSzz6tjcMmrVbAOade0K2gkss2vZ7HIate3DWzQ8Itu53bPqNW2KcqT9yvKpvBNi9X0LMsR8S7PAtnzM9PMROek2IuUh5hp9QWYSzeEOugMD/JSKgo1FalMdRI/H8PAxt2ndbZLJzOhSwcTgUsDFbZLHxOOSwMlnsZQVJmnhG8jr5hIs6+oRJ23mHCIOzkGyam5pnCDpIX8ChhEfMpZ2G0zWUBuo5F3LeSBQAHLAwDzrvbogAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"microservices\"\n        title=\"\"\n        src=\"/static/9787c4f6a7d8c18e97cc988918fecd57/42603/microservices.png\"\n        srcset=\"/static/9787c4f6a7d8c18e97cc988918fecd57/f931c/microservices.png 200w,\n/static/9787c4f6a7d8c18e97cc988918fecd57/e8031/microservices.png 400w,\n/static/9787c4f6a7d8c18e97cc988918fecd57/42603/microservices.png 800w,\n/static/9787c4f6a7d8c18e97cc988918fecd57/5b8b9/microservices.png 1200w,\n/static/9787c4f6a7d8c18e97cc988918fecd57/c7ea5/microservices.png 1600w,\n/static/9787c4f6a7d8c18e97cc988918fecd57/70d9e/microservices.png 1778w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n      />\n  </span>\n  </a></p>\n<p>Microservice has been a game changer in software development in the last few years, yet it remains a grey area when it comes to making decision around maintainability and implementation of microservices. The evangelists behind microservice approach have built the case around speed, scalability and cohesion stating in that a microservice Change is easy, Units are small, scalability is semi-infinite. So what is Microservice architecture? Microservices — also known as the microservice architecture — is an architectural style that structures an application as a collection of loosely coupled services, which implement business capabilities.</p>\n<p>We will discuss and summarise some of the implementation factors that have a big impact on indicators of success in your project/software delivery viz:</p>\n<p><strong>Law of repository management</strong></p>\n<p>One of the most active moving parts of microservices is code repositories. They can be categorised into two broader areas.</p>\n<ul>\n<li>Mono Repository i.e. keep all the services in the same repository</li>\n<li>Multiple Repositories i.e. keep separate repositories for each of the services</li>\n</ul>\n<p>Majority of microservices evolve over a period of time and it has been observed that based on team and organisation structures derives the strategy adopted for code management. Usually, it naturally tends towards multiple repository pattern due to diverse practices followed in an organisation among various units. This results in poor code re-usability but also provides clear boundaries of ownership. The problem of re-usability can be resolved by implementing a re-usable package, e.g. nuGet for C#, Packet for F# or npm for node etc. As the number of services grows it becomes difficult to debug and cross teams development. Moreover, overall platform knowledge becomes fragmented and abstract due to focused development teams.</p>\n<p>For a larger project, it is recommended to use Mono repository with clear segregation of domain functionality and shared core re-usability. This brings standardisation in development style and practices. It provides better integration capabilities and debugging at the cost of a larger code base. Most programming framework provides a modular development approach where we can leverage best of both worlds of mono repo for development and multi repo for build and release.</p>\n<p><strong>Law of separation of concern</strong></p>\n<p>The most common dilemma that microservice brings into an architects plate is regarding granularity of functionality. As per recommended practice, the domain driven development leads to correct size of bounded context which is articulated based on various business activities and influence. Usually, in the real world, it has been noticed that business units are generated based on software boundaries. Nevertheless using microservices does not imply less code, rather it focuses on maintainability and scalability. If you are planning to create a microservice for each function then you are definitely planning for a disaster. Though segregation shall be based on the business domain but under special scenarios it is absolutely acceptable to deviate and create a separate service based on technical feature, e.g. email service, notification service etc.</p>\n<p>The mutual independence across multiple microservices is the core principle behind this architecture. Each service shall ideally implement its own data persistence and caching capabilities. The owner service defines the strategy to create, manipulate and consume service. The external services should not be entertaining data access directly but shall only pass through owner service interfaces only.</p>\n<p>The cross-cutting concerns such as security shall be abstracted to gateways such as azure API management, <a href=\"http://threemammals.com/ocelot\">ocelot</a>. In certain scenarios, an aggregator microservice might be required from the client or as a server wrapper to avoid multiple dependency hell.</p>\n<p>For a more complex front end, a small microservice shall be created for each unit of a user interface to process data and serve it to the client. This pattern is usually known as UI microservice or backend for front end design.</p>\n<p><strong>Law of eventual consistency</strong></p>\n<p>Since each service is responsible for consistency and reliability of its data, the cross domain data passing is performed via message passing. It does not result in ACID [atomic, consistent, isolated, durable] principles as these updates are not happening in the transaction. This is can be solved using two-phase commit but will eventually result in high coupling and the core principle of microservices are violated. The microservice architecture is an advocate of CAP theorem i.e. consistent, available and partition tolerant. To achieve the desired benefits of microservices the eventual consistency is implemented via</p>\n<ul>\n<li>\n<p>Event sourcing - We can query an application’s state to find out the current state of the world, and this answers many questions. However, there are times when we don’t just want to see where we are, we also want to know how we got there. Event Sourcing ensures that all changes to application state are stored as a sequence of events. Not just can we query these events, we can also use the event log to reconstruct past states, and as a foundation to automatically adjust the state to cope with retroactive changes. e.g. database event logs, similar implementation can be adopted for business events and each microservices can perform action independently to bring the system to the desired state eventually.</p>\n</li>\n<li>\n<p>CQRS - CQRS stands for Command Query Responsibility Segregation. It’s a pattern that I first heard described by Greg Young. At its heart is the notion that you can use a different model to update information than the model you use to read information. The microservice can process data and keep up to date information for serving Realtime need but can update the core system from the log. e.g. a notification for e-commerce order placement can be served separately to update in ERP system.</p>\n</li>\n<li>\n<p>Message/Service Bus - For event-based message passing in microservice either a direct call to the service can be initiated or a message broker such as service bus can be implemented for asynchronous communication maintaining the high demand services to scale to serve client needs and keeping background jobs instance low.</p>\n</li>\n</ul>\n<p>The above eventual consistency also require coordination of execution. The solution is defined as a saga. Implement each business transaction that spans multiple services as a saga. A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.</p>\n<p>There are two ways of coordination sagas:</p>\n<ul>\n<li>Choreography - each local transaction publishes domain events that trigger local transactions in other services</li>\n<li>Orchestration - an orchestrator (object) tells the participants what local transactions to execute</li>\n</ul>\n<p><strong>Law of scalable deployment</strong></p>\n<p>Easy deployment and scalability are the key features that bought microservices into the architects toolbox. There are various containerisation frameworks/application that can compile into the deployable image that is ready to scale. Application containerisation is an OS-level virtualisation method which is used to deploy and run distributed applications without launching an entire virtual machine (VM) for each app. Multiple isolated applications or services run on a single host and access the same OS kernel. Application containers include the runtime components — such as files, environment variables and libraries — necessary to run the desired software. Application containers consume fewer resources than a comparable deployment on virtual machines because containers share resources without a full operating system to underpin each app.</p>\n<p>The most common app containerisation technology is Docker, specifically the open source Docker Engine and container based on universal runtime runC. The main competitive offering is CoreOS’ rkt container engine that relies on the App Container (appc) spec as its open, standard container format, but it also can execute Docker container images.</p>\n<p>Though containerisation is not required to develop and run microservices, but these two concepts have been tied together as complementary services to generate maximum benefit. The recommended practice is to deploy services using orchestrator such as Azure Kubernetes services, AWS Fargate where that can create an instance for public or private registry such as docker hub, Azure container service etc. You can deploy multiple containers on one host or have one host per container.</p>\n<p>Now Azure app service has the capability to run docker image but usually with orchestrators in place, a cluster such as a the docker swarm, Azure service fabric, Azure service fabric mesh is usually used as deployment engine.</p>\n<p>Since this dynamic addition or removal of images may result in multiple end-points thus a service discover provider is required to let the traffic get routed to healthy end points only.</p>\n<p><strong>Law of greenfield initiation</strong></p>\n<p>When working on a greenfield project; multiple design patterns help us structure the system. But following key principles are must have for robust system viz:</p>\n<ul>\n<li>\n<p>Resilience - When a system is under faulty state due to certain unexpected events, the microservice shall be monitored correctly and a new backup service shall immediately become active to minimise the loss of data. If the service or backup is not available then alternate application to keep track of operation shall cover during the downtime. Failure in one service shall not affect other.</p>\n</li>\n<li>\n<p>Failure - This is an extension of the above-mentioned principle. If a service fails then the dependent service shall have some mechanism to track status and reduce resource wastage. The service might fail temporarily due to some network issue, thus a retry policy shall be applied. A more advanced mechanism would be implementing circuit breaker where after a certain retry it stops sending more message to failed microservice and only passes certain requests in between to check for resume the status.</p>\n</li>\n<li>\n<p>Availability - Apart from expected and unexpected coding fault recovery, the ability to maintain uptime is the core requirement. Thus having geo-distributed redundant implementation shall be a part of the implementation strategy.  For high availability, a blue-green pattern makes sure zero downtime during maintenance and upgrades. </p>\n</li>\n<li>\n<p>Dev-ops - With the highly scalable environment the automated deployment and ability to version control the services leads to a stable solution. The service discover shall consider service versioning before routing requests.</p>\n</li>\n<li>\n<p>Scalability - Using ready to deploy lightweight images as container shall allow individual service to scale to meet the growing demand.</p>\n</li>\n</ul>\n<p><strong>Law of brownfield transition</strong></p>\n<p>When transitioning from a brownfield project, more effort is required to make sure the stability of the system is not affected. In these scenarios, the Strangler pattern comes to the rescue. The Strangler pattern is based on an analogy to a vine that strangles a tree that it’s wrapped around with. This solution works well with web applications, where a call goes back and forth, and for each URI call, a service can be broken into different domains and hosted as separate services. The idea is to do one domain at a time. This creates two separate applications that live side by side in the same URI space. Eventually, the newly refactored application “strangles” or replaces the original application until finally, you can shut off the monolithic application.</p>\n<p>Apart from strangler, an anti-corruption layer implements a facade between new and legacy applications, to ensure that the design of a new application is not limited by dependencies on legacy systems.</p>\n<p><strong>Law of implementation patterns</strong></p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/79ac331adc47053b80ac4ed091f7e727/4e41a/microservice2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 800px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 70.33299697275478%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAABJ0AAASdAHeZh94AAADVklEQVQoz0WSfUwTdxjHf0MzF+P+2X+aZS5GXROqgDOLiy+ZummyZC/RxGXRxOmIjiBvYi20g5a2UMq6hSID+gIGDRtgtiEwgXJtabH0erYMtXBdpUKztsD1WqAc7fV6vdvBYvbkyZM8T76f5Ps8ecCWYiO/1p6mMyzLEknqgMwJrpveEdnjBFM28zPfkn9l6geKSWdYKsUkKSZF0TT7KgAohHhyRzqzAa+lktn3GoGwY2+HJk4SFwaMbzTpP/9j5Ck2f2xYcsIo4/WX3nA3W30R2ZC/buQl2CGw5NXD+MoaQZChGH7SIgQS+RHoNpZY/LJ1dpvQ85nOb/IEtpX/vrUMApUNZx/fUg553xJad4pt4F3p49NNrlg8waTZpfjyR0YJqG7IG6gIRENfdXl2qZ6cu4/isdSfU8s9CN71l280PJnJMBSd4RJklZoO1jtJmlqnk6sUcWpMDOTq7IflvqVgKBHt/Qd6tDDuJV4EySDN/L/tq52vPuJXI70++1GTIEGReX1SUPXT4eHK2WiYTbG53erXWiuyNAVbe89P44E0xSF0hz3wcbP71B03uNQ5Jeuf70KtB6Ci5XiCJ4FB+S8fmItDBJ5aJ79oRvk1aK7CfXhI7F8J0hzM0P1T4evdMwU9M6Cwx9MIBc1Lzz40CnwBLLv2CSgZ2K/VLqzFmVTma4vm2KD0SL/o+KgwSET+cxteSdhe4PBcFID8DduGZ9DbDy+HsXiOEtkusO8Ww4urJEvTPPVvoOrXLd/rtj+4OIPP0yTHZhSDvtfLxt4UWAEohg6p3E9jcyJ3ZziyWtLnutA5ce0B/Hd0CVvHRQPPv7k3ebXLmW9vnY7NRRKrWHJ5GluEZufN/gDYVTV+QuMi0xuXdAf9uZbC98eLuORBhftGC45O3PxkouIMLPrUUZNjLt0zfG334LfvGb/LtRXnWItAVomJr4SpTTiwgI14HJAXgVDE7EVMqJOr3Q5T36TN7OOGsCuE+pOLrrB3Q4YiANyAeApHevNjp9GX0kpJvbRWKVFwtbFe3aj6sUGmrKuWq2rqqgVim2mMk41DtjqJXK1QcfAIT26nN2Esgje3tmj12jadtk2vNdxtb7/boTPouFZn0GvuNDkQmJPBiLOlrUXfbvgXcOE7WGWEUeIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"microservices\"\n        title=\"\"\n        src=\"/static/79ac331adc47053b80ac4ed091f7e727/42603/microservice2.png\"\n        srcset=\"/static/79ac331adc47053b80ac4ed091f7e727/f931c/microservice2.png 200w,\n/static/79ac331adc47053b80ac4ed091f7e727/e8031/microservice2.png 400w,\n/static/79ac331adc47053b80ac4ed091f7e727/42603/microservice2.png 800w,\n/static/79ac331adc47053b80ac4ed091f7e727/4e41a/microservice2.png 991w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n      />\n  </span>\n  </a></p>\n<p>Image Source : <a href=\"https://azure.microsoft.com/en-au/blog/design-patterns-for-microservices/\">Microsoft blog</a></p>\n<p>The eight core widely used microservices are that every architect shall know for high-performance systems includes</p>\n<ul>\n<li>Ambassador can be used to offload common client connectivity tasks such as monitoring, logging, routing, and security (such as TLS) in a language agnostic way.</li>\n<li>Anti-corruption layer implements a facade between new and legacy applications, to ensure that the design of a new application is not limited by dependencies on legacy systems.</li>\n<li>Backends for Frontends creates separate backend services for different types of clients, such as desktop and mobile. That way, a single backend service doesn’t need to handle the conflicting requirements of various client types. This pattern can help keep each microservice simple, by separating client-specific concerns.</li>\n<li>Bulkhead isolates critical resources, such as connection pool, memory, and CPU, for each workload or service. By using bulkheads, a single workload (or service) can’t consume all of the resources, starving others. This pattern increases the resiliency of the system by preventing cascading failures caused by one service.</li>\n<li>Gateway Aggregation aggregates requests to multiple individual microservices into a single request, reducing chattiness between consumers and services.</li>\n<li>Gateway Offloading enables each microservice to offload shared service functionality, such as the use of SSL certificates, to an API gateway.</li>\n<li>Gateway Routing routes requests to multiple microservices using a single endpoint, so that consumers don’t need to manage many separate endpoints.</li>\n<li>Sidecar deploys helper components of an application as a separate container or process to provide isolation and encapsulation.</li>\n<li>Strangler supports incremental migration by gradually replacing specific pieces of functionality with new services.</li>\n</ul>\n<p><strong>Law of communication</strong></p>\n<p>For making maintainable microservices it is important to abstract the dependencies. Ambassador pattern can be used to offload common client connectivity tasks such as monitoring, logging, routing, and security (such as TLS) in a language agnostic way.</p>\n<p>Another important communication aspect to consider is sync vs async inter-service communication. Having a sync request-response is an anti-pattern and causes bottleneck. The recommended approach is implementing async communication using message broker, hooks or observers</p>\n<p><strong>Law of Monitoring</strong></p>\n<p>With the implementation of multiple microservices, traditional methods of monitoring will not provide required enterprise scale monitoring and health check. The five key principles of monitoring that shall be included in your strategy are:</p>\n<ul>\n<li>Monitor containers and what’s inside them.</li>\n<li>Alert on service performance, not container performance.</li>\n<li>Monitor services that are elastic and multi-location.</li>\n<li>Monitor APIs.</li>\n<li>Map your monitoring to your organisational structure.</li>\n</ul>\n<p>By practising the above laws an architect can create a robust solution, using microservices.</p>","frontmatter":{"date":"January 28, 2019","title":"9 laws of architecting microservices"}}},{"node":{"id":"83fca52e-f506-543b-bb37-b7d9695f772c","excerpt":"A concurrent program has multiple logical threads of control. These threads may or may not run in parallel. A parallel program potentially…","fields":{"slug":"/2019-01-04-elixir-concurrency-models/"},"html":"<p>A concurrent program has multiple logical threads of control. These threads may or may not run in parallel. A parallel program potentially runs more quickly than a sequential program by executing different parts of the computation simultaneously (in parallel). It may or may not have more than one logical thread of control. An alternative way of thinking about this is that concurrency is an aspect of the problem domain—your program needs to handle multiple simultaneous (or near-simultaneous) events. Parallelism, by contrast, is an aspect of the solution domain—you want to make your program faster by processing different portions of the problem in parallel.</p>\n<p>Functional programming avoids the problems associated with a shared mutable state by avoiding mutable state. Actor programming, by contrast, retains mutable state but avoids sharing it. An actor is like an object in an object-oriented (OO) program—it encapsulates state and communicates with other actors by exchanging messages. The difference is that actors run concurrently with each other and, unlike OO-style message passing (which is really just calling a method), actors really communicate by sending messages to each other.</p>\n<p>Certainly, there are some concurrent programs that will always be non-deterministic. And this is unavoidable—some problems require solutions that are intrinsically dependent on the details of timing. But it’s not the case that all parallel programs are necessarily non-deterministic. The value of the sum of the numbers between 0 and 10,000 won’t change just because we add those numbers together in parallel instead of sequentially</p>\n<p>Microsoft <a href=\"https://dotnet.github.io/orleans/\">Orleans</a> is .net implementation of Actor Model but we will focus on programming language which was built with a focus on concurrent execution. Elixir/Erlang: Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability. Some of its uses are in telecoms, banking, e-commerce, computer telephony and instant messaging. Erlang’s runtime system has built-in support for concurrency, distribution and fault tolerance.\nOTP is a set of Erlang libraries and design principles providing middle-ware to develop these systems. It includes its own distributed database, applications to interface towards other languages, debugging and release handling tools. Erlang runs on VM called BEAM which is essentially a <a href=\"https://en.wikipedia.org/wiki/Virtual_machine\">process virtual machine</a></p>\n<blockquote>\n<p>In Erlang, and therefore Elixir, an actor is called a process. In most environments, a process is a heavyweight entity that consumes lots of resources and is expensive to create. An Elixir process, by contrast, is very lightweight—lighter weight even than most systems’ threads, both in terms of resource consumption and startup cost. Elixir programs typically create thousands of processes without problems and don’t normally need to resort to the equivalent of thread pools</p>\n</blockquote>\n<p><strong>Elixir actor by example</strong>  </p>\n<p>Elixir actors communicate via message passing using mailboxes, which are queues by data structure. For our example, we will create a md5 hash generator which based on a string return a md5 value of a string. If the value is already exiting it will not recompute to save CPU resource but send it from in-memory cache.</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt; IO.puts(&quot;#{value}&quot;)</code> will replace #{value} with computed hash function<br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">pid = spawn(&amp;HashIt.loop/0)</code><br>\n<code class=\"language-text\">send(pid, {:compute, &quot;bipin&quot;})</code><br>\n<code class=\"language-text\">sleep(1000)</code>  </p>\n<p>This function implements an infinite loop by calling itself recursively. The receive block waits for a message and then uses pattern matching to work out how to handle it.  Elixir implements tail-call elimination. Tail-call elimination, as its name suggests, replaces a recursive call with a simple jump if the last thing the function does is call itself, thus infinite recursive call o loop function will not result in stack overflow.</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt; IO.puts(:crypto.hash(:md5, value) |&gt; Base.encode16())</code><br>\n           <code class=\"language-text\">{:shutdown} -&gt;  -&gt; exit(:normal)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">receive do</code><br>\n   <code class=\"language-text\">{:EXIT, ^pid, reason} -&gt; IO.puts(&quot;HasIt has exited (#{reason})&quot;)</code><br>\n<code class=\"language-text\">end</code></p>\n<p><code class=\"language-text\">Process.flag(:trap_exit, true)</code><br>\n<code class=\"language-text\">pid = spawn_link(&amp;HashIt.loop/0)</code><br>\n<code class=\"language-text\">send(pid, {:compute, &quot;bipin&quot;})</code><br>\n<code class=\"language-text\">send(pid, {:shutdown}</code>  </p>\n<p><strong>Adding state to the actor</strong>  </p>\n<p>We will add a variable to store all values sent and their computed hash</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def loop(strg) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value} -&gt;</code><br>\n               <code class=\"language-text\">hashValue = :crypto.hash(:md5 , value) |&gt; Base.encode16()</code><br>\n               <code class=\"language-text\">updatedStrg = strg.put(strg, value, hashValue)</code><br>\n               <code class=\"language-text\">IO.puts(hashValue)</code><br>\n               <code class=\"language-text\">loop(updatedStrg)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p>Here Strg is an elixir Map and we can start the process by using  </p>\n<p><code class=\"language-text\">pid = spawn(HashIt, :loop, [%{}])</code>  </p>\n<p>or we can define methods to start, compute also provide it a name instead of using pid by registering it.  </p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def start(name, strg, cryptoType) do</code><br>\n       <code class=\"language-text\">pid = spawn(__MODULE__, :loop, [strg, cryptoType])</code><br>\n       <code class=\"language-text\">Process.register(pid, name)</code><br>\n       <code class=\"language-text\">pid</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def compute(name, value) do</code><br>\n       <code class=\"language-text\">ref = make_ref()</code><br>\n       <code class=\"language-text\">send(name, {:compute, value, self(), ref})</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:ok, ^ref, reply} -&gt; reply</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop(strg, cryptoType) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value, sender, ref} -&gt;</code><br>\n               <code class=\"language-text\">hashValue = :crypto.hash(cryptoType , value) |&gt; Base.encode16()</code><br>\n               <code class=\"language-text\">updatedStrg = Map.put_new(strg, value, hashValue)</code><br>\n               <code class=\"language-text\">send(sender, {:ok, ref, hashValue})</code><br>\n               <code class=\"language-text\">loop(updatedStrg, cryptoType)</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p>The program can be started via start method and uses pseudo-variable <strong>MODULE</strong>, which evaluates to the name of the current module. The Process.register registers the pid as name :hashit. Moreover, instead of printing the hash value it now returns it to the sender, which helps in bi-directional communication. The carot ^ symbol in {:ok, ^ref, reply} denotes we want to match the value rather than binding it. The <a href=\"https://elixir-lang.org/getting-started/pattern-matching.html\">pattern matching</a> in elixir is used to match inside a data structure. Effectively we can now execute the HashIt module via</p>\n<p><code class=\"language-text\">:hashItMD5 |&gt; HashIt.start([%{}, :md5])</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; HashIt.compute(&quot;bipin&quot;)</code></p>\n<p><strong>Adding check and compute logic</strong>  </p>\n<p>Adding the return value to check in the cache before recomputing above module can be refactored as</p>\n<p><code class=\"language-text\">defmodule HashIt do</code><br>\n   <code class=\"language-text\">def start(name, strg, cryptoType) do</code><br>\n       <code class=\"language-text\">pid = spawn(__MODULE__, :loop, [strg, cryptoType])</code><br>\n       <code class=\"language-text\">Process.register(pid, name)</code><br>\n       <code class=\"language-text\">pid</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def compute(name, value) do</code><br>\n       <code class=\"language-text\">ref = make_ref()</code><br>\n       <code class=\"language-text\">send(name, {:compute, value, self(), ref})</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:ok, ^ref, reply} -&gt; reply</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop(strg, cryptoType) do</code><br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:compute, value, sender, ref} -&gt;</code><br>\n               <code class=\"language-text\">result = Map.fetch(strg, value)</code><br>\n               <code class=\"language-text\">case result do</code><br>\n                   <code class=\"language-text\">{:ok, val} -&gt; send(sender, {:ok, ref, val})</code><br>\n                        <code class=\"language-text\">loop(strg, cryptoType)</code><br>\n                   <code class=\"language-text\">{:error, _reason} -&gt;</code><br>\n                        <code class=\"language-text\">hashValue = :crypto.hash(cryptoType , value) |&gt; Base.encode16()</code><br>\n                        <code class=\"language-text\">updatedStrg = Map.put_new(strg, value, hashValue)</code><br>\n                        <code class=\"language-text\">send(sender, {:ok, ref, hashValue})</code><br>\n                        <code class=\"language-text\">loop(updatedStrg, cryptoType)</code><br>\n               <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">end</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p><strong>Making it fault tolerant</strong>  </p>\n<p>Thus various processes can be started in parallel for different crypto compute example MD5, SHA128, SHA256. Using the above process mechanism we can create multiple processes for different or same task resulting in both concurrent and parallel deterministic outputs. But this architecture does not provide fault tolerance. What if there is an error and it is aborted abruptly? Elixir provides a mechanism to link it to a process which is bi-directional.  </p>\n<p><code class=\"language-text\">:hashItMD5 |&gt; HashIt.start([%{}, :md5])</code><br>\n<code class=\"language-text\">:hashItSHA256 |&gt; HashIt.start([%{}, :sha256])</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; Process.link(:hashItSHA256)</code><br>\n<code class=\"language-text\">:hashItMD5 |&gt; exit(:forced_kill)</code>  </p>\n<p>Since we are using spawn in our hash, We can also use spawn_link method to link process instead of process.link(). Please note links created are bi directional. and calling abnormal exit on :hashItMD5 will also set :hashItSHA256 to nil  </p>\n<p><code class=\"language-text\">Process.info(:hashItMD5, :status)</code><br>\n<small>nil</small><br>\n<code class=\"language-text\">Process.info(:hashItSHA256, :status)</code><br>\n<small>nil</small>  </p>\n<p>but normal exit will keep the linked process active, viz:<br>\n<code class=\"language-text\">:hashItMD5 |&gt; exit(:normal)</code><br>\n<code class=\"language-text\">Process.info(:hashItMD5, :status)</code><br>\n<small>nil</small><br>\n<code class=\"language-text\">Process.info(:hashItSHA256, :status)</code><br>\n<small>{:status, :waiting}</small>  </p>\n<p>This implies we can set the system trap to capture other processes exit, when can be utilized to create supervisor and restart the system if the process crashes. We can set Process.flag(:trap_exit, true) to capture the exit of linked process and take appropriate action. In our example of HashIt, a supervisor can be created as:  </p>\n<p><code class=\"language-text\">defmodule HashItSupervisor do</code><br>\n   <code class=\"language-text\">def start do</code><br>\n       <code class=\"language-text\">spawn(__MODULE__, :loop_system,[])</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop_system do</code><br>\n       <code class=\"language-text\">Process.flag(:trap_exit, true)</code><br>\n       <code class=\"language-text\">loop</code><br>\n   <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">def loop do</code><br>\n       <code class=\"language-text\">pid = HashIt.start(%{}, :md5)</code> // instead of using spawn please change it to spawn_link in HashIt module<br>\n       <code class=\"language-text\">receive do</code><br>\n           <code class=\"language-text\">{:EXIT, ^pid, :normal} -&gt; IO.puts(&quot;Hash It exited normally&quot;)</code><br>\n               <code class=\"language-text\">:ok</code><br>\n           <code class=\"language-text\">{:EXIT, ^pid, reason} -&gt; IO.puts(&quot;Hash It failed with reason #{inspect reason}...restarting&quot;)</code><br>\n               <code class=\"language-text\">loop</code><br>\n       <code class=\"language-text\">end</code><br>\n   <code class=\"language-text\">end</code><br>\n<code class=\"language-text\">end</code><br>\n<code class=\"language-text\">----------</code><br>\n<code class=\"language-text\">HashItSupervisor.start</code>  </p>\n<p>If the HashIt system now crashes it is captured by HashItSupervisor and is restarted. If the two processes are dependent on each other and can result in deadlock or infinite waiting because of crashing of sender the receiver can be guarded using timeout clause in receive do loop by using after clause. example:</p>\n<p><code class=\"language-text\">receive do</code><br>\n   <code class=\"language-text\">{:ok, ^ref, value} -&gt; IO.puts(value)</code><br>\n   <code class=\"language-text\">after 1000 -&gt; nil</code><br>\n<code class=\"language-text\">end</code>  </p>\n<p><strong>Scaling to multiple nodes/computers</strong>  </p>\n<p>The actor programming naturally supports an approach to writing fault-tolerant code that leverages this observation: the error-kernel pattern. In the elixir system, the kernel is the root supervisor which can start other supervisors or workers. When we create an elixir virtual machine we create a node we can create nodes multiple nodes on the same system or on network of computer by naming them using —name or —sname option. To make multiple nodes part of the same cluster it must use same —cookie name argument. This results in running your system across multiple systems. To multiple connect nodes we can use connect function</p>\n<p><code class=\"language-text\">iex(node1@192.168.0.10)1&gt; Node.self</code><br>\n<small>:“node1@192.168.0.10”</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)2&gt; Node.list</code><br>\n<small>[]</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)3&gt; Node.connect(:&quot;node2@192.168.0.20&quot;)</code><br>\n<small>true</small><br>\n<code class=\"language-text\">iex(node1@192.168.0.10)4&gt; Node.list</code><br>\n<small>[:“node2@192.168.0.20”]</small>  </p>\n<p>Now use Node.Spwan to start worker or supervisors and use :global.register_name() instead of Process.register() to make names cluster global. </p>\n<p><strong>Important notes</strong>  </p>\n<p>For this explanatory purpose, we used dynamic atom naming above. However, naming dynamic processes with atoms is a terrible idea! If we use atoms, we would need to convert the name (often received from an external client) to atoms, and we should never convert user input to atoms. This is because atoms are not garbage collected. Once an atom is created, it is never reclaimed. Generating atoms from user input would mean the user can inject enough different names to exhaust our system memory!  </p>\n<p>In practice, it is more likely you will reach the Erlang VM limit for the maximum number of atoms before you run out of memory, which will bring your system down regardless. Moreover, supervisor model used above can result in inconsistent naming convention across various modules and libraries. Thus elixir provides a standard protocol for defining, starting and maintaining workers using efficient bucketed methodology using <a href=\"https://elixir-lang.org/getting-started/mix-otp/genserver.html\">GenServer</a>, providing standard call, cast and info method implementation for various operation.</p>","frontmatter":{"date":"January 04, 2019","title":"phoenix/elixir - concurrency actor model with 'let it crash' philosophy"}}}]}},"pageContext":{"tag":"technology"}}